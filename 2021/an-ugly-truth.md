# An Ugly Truth

Sheera Frenkel, Cecilia Kang (2021) • Amazon

***

"An Ugly Truth" by Sheera Frenkel and Cecilia Kang is a comprehensive exploration of the social media giant, Facebook, its founders, and the issues that have shaped the company's trajectory. The book sheds light on the company's internal struggles, controversies, and the challenges it has faced regarding privacy breaches, election interference, misinformation, and the impact on democratic processes.

The authors begin by setting the stage with an overview of Mark Zuckerberg's three greatest fears and the pivotal events that unfolded in Facebook's story. They delve into the company's ruthless tactics to eliminate competitors, accusations of privacy abuse and enabling harmful content, and the role of key figures like Mark Zuckerberg and Sheryl Sandberg. The growth-at-any-cost strategy, the lack of competition, and the proliferation of misinformation on Facebook's platforms are examined in detail.

The book explores significant chapters in Facebook's journey, including the controversies surrounding content moderation, the Russian hacking activities during the 2016 US presidential elections, and the infamous Cambridge Analytica scandal. It highlights the internal conflicts within the company, the struggles of its security team, and the mounting criticism faced by Facebook's leadership.

Furthermore, the authors delve into the impact of Facebook on society, including its role in exacerbating racial tensions in Myanmar and the spread of hate speech. The book covers the challenges of addressing misinformation, the platform's response to the 2020 US presidential election, and the company's attempts to navigate political speech while preventing harm.

Throughout the narrative, the authors examine the complex dynamics within Facebook, the conflicts of interest between growth and user safety, and the mounting pressure from lawmakers, civil rights leaders, and the public. They also discuss the formation of coalitions against Facebook, the legal battles faced by the company, and the establishment of the Facebook Oversight Board.

In the epilogue, the authors reflect on Facebook's response to the challenges and the potential transformations the company may undergo. They emphasize the enduring success of Facebook, its financial performance, and its role in reshaping society, while acknowledging ongoing concerns about privacy, safety, and the integrity of democratic systems.

"An Ugly Truth" offers readers an in-depth and critical examination of Facebook, presenting a comprehensive account of the company's history, controversies, and the implications of its actions. The book raises important questions about the power and responsibility of social media platforms in the modern age.

***

## At Any Cost

In this chapter, the stage is set for the pivotal events that unfold in the story of Facebook. The chapter begins with an overview of Mark Zuckerberg's three greatest fears: hacking, physical harm to employees, and regulatory intervention. The narrative then jumps to December 9, 2020, when the Federal Trade Commission and numerous states sue Facebook, seeking to dismantle the company for harming its users and competitors.

New York State Attorney General Letitia James holds a press conference, outlining the case against Facebook. The allegations include Facebook's ruthless "buy-or-bury" strategy to eliminate competitors, resulting in a powerful monopoly. The company is accused of abusing user privacy and enabling toxic and harmful content to reach billions of people. Mark Zuckerberg is portrayed as a rule-breaking founder who used bullying tactics and deception to maintain dominance. Sheryl Sandberg, Facebook's COO, is depicted as the driving force behind the pernicious advertising business that surveils users for personal data.

The chapter highlights how Facebook's growth-at-any-cost strategy was centered on the exchange of users' time, attention, and personal data for free access to the service. Sandberg's role in scaling this model is emphasized, as she oversaw departments that didn't interest Zuckerberg and presented a more palatable image of Facebook to investors and the public.

The government officials and regulators assert that Facebook's lack of competition led to a proliferation of misinformation and objectionable content on its platforms. Despite major controversies, users remained on the platform due to the absence of viable alternatives.

The chapter concludes by mentioning the authors' own investigation into Facebook, which provides unique insights into the company's inner workings. It suggests that Zuckerberg and Sandberg deliberately designed Facebook's business model and that the company's failures and vulnerabilities were exposed within a five-year period, spanning one U.S. election to another.

Overall, the chapter sets the stage for a deeper exploration of the complex story of Facebook, its founders, and the issues that shaped the company's trajectory.

## Don't Poke the Bear

In this chapter titled "Don't Poke the Bear," significant events and decisions involving Facebook and its response to critical issues are explored. The chapter begins with a Facebook engineer taking advantage of the company's open access to user data, illustrating the lack of safeguards and accountability. The engineer's actions highlight the systemic problem of employees misusing private information.

The chapter then delves into a pivotal meeting in September 2015, where Facebook's new chief security officer, Alex Stamos, presents a comprehensive evaluation of the company's security flaws. Stamos reveals that numerous engineers had been inappropriately accessing user data, emphasizing the need for proactive prevention rather than simply firing offenders after the fact. This revelation shocks Mark Zuckerberg and the other executives, leading to discussions about overhauling the system and limiting access to user data.

The narrative shifts to the dilemma Facebook faced when Donald Trump's campaign posted an anti-Muslim speech on the platform. Executives, including Joel Kaplan, advise against removing the post, fearing accusations of bias and censorship. The concept of "newsworthiness" is introduced to protect political speech, allowing users to form their own opinions. This decision raises questions about Facebook's evolving definition of hate speech and its commitment to unbiased content moderation.

Joel Kaplan, Facebook's head of global public policy, emerges as a key figure in protecting the company's interests in Washington. His conservative background and expertise play a role in shaping Facebook's political approach. The chapter also highlights the significant influence Trump's campaign had on Facebook, utilizing the platform's microtargeting tools and amplifying campaign ads, ultimately reshaping the landscape of political campaigning.

The chapter concludes with a Q&A session where Mark Zuckerberg defends the decision to keep Trump's controversial post on the platform, citing free expression as a core value. The debate around the role of Facebook in promoting a healthy society and the potential dangers of algorithmic amplification is raised.

Overall, "Don't Poke the Bear" explores the complex challenges Facebook faced in dealing with privacy breaches, political content moderation, and the growing impact of social media on politics.

## The Next Big Thing

In this chapter, titled "The Next Big Thing," the focus is on the pivotal moments and decisions that shaped Facebook's growth and its impact on the social media landscape. The chapter begins with Mark Zuckerberg's meeting with Don Graham, the CEO of The Washington Post, who recognized the potential of Thefacebook and offered a $6 million investment. However, Zuckerberg faced a moral dilemma when he received a more lucrative offer from the venture capital firm Accel Partners. Ultimately, he chose Accel Partners and its approach of focusing on user growth and innovation rather than immediate profitability.

The chapter explores the launch of News Feed, a feature that revolutionized Facebook by providing a personalized stream of updates from users' friends. While News Feed faced initial backlash and privacy concerns, Zuckerberg's belief in its potential led to a significant increase in user engagement. Despite protests and criticisms, Zuckerberg issued a public apology that set the tone for how Facebook would handle future crises—a combination of listening to user feedback, emphasizing personal responsibility, and maintaining a focus on growth.

The lack of editorial guidelines and content policies at Facebook becomes apparent as the company deals with controversial advertisements and the challenges of defining acceptable content. The chapter highlights the informal and ad hoc approach to content moderation and the need for Facebook to address these issues as it expands and gains more influence.

As Facebook continues to grow and attract millions of users, the chapter delves into the company's evolving business strategy and the pressure to monetize its platform. It becomes clear that while Zuckerberg excelled at conceptualizing and building Facebook, he had little enthusiasm for traditional business aspects. The chapter concludes with Zuckerberg contemplating the role of CEO and the possibility of hiring someone else to handle the managerial responsibilities, allowing him to focus on generating new ideas.

"The Next Big Thing" captures the critical moments in Facebook's journey, from strategic partnerships and controversial feature launches to the challenges of content moderation and the need to balance growth with monetization. It sets the stage for the next phase of Facebook's evolution as it seeks to connect more users and establish itself as a dominant player in the tech industry.

## What Business Are We In?

In this chapter, titled "What Business Are We In?", the focus is on the evolving business model of Facebook and the challenges it faced during its growth. Sheryl Sandberg's role as the Chief Operating Officer comes into play as she tries to assert herself and strengthen the ad business of Facebook. However, she faces obstacles in capturing Mark Zuckerberg's attention and obtaining the necessary resources for growth.

The chapter delves into the introduction of Facebook's ad initiatives, including the controversial Beacon program, which faced public backlash for its invasive nature. Sandberg's hiring brings a new phase of advertising to Facebook, with the development of the Like button, a feature that quickly gains popularity among users. The Like button not only enhances user engagement but also becomes a powerful tool for collecting insights into users' preferences.

As Facebook continues to expand, it faces competition from Twitter, prompting Zuckerberg to make changes to privacy settings in an effort to capture the excitement surrounding the public nature of Twitter. However, these changes ignite a storm of anger from users and draw attention from regulators concerned about privacy issues. The chapter highlights the clash between Facebook's cavalier stance toward user data and the growing scrutiny from government officials.

The chapter concludes by highlighting the complaint filed against Facebook by privacy groups and the subsequent investigation by the Federal Trade Commission (FTC). Although the FTC settlement subjects Facebook to privacy audits, the government's oversight of the company remains limited until Facebook's later period of crisis in 2016.

Overall, "What Business Are We In?" examines the complexities and controversies surrounding Facebook's business decisions, its handling of user data, and the growing regulatory scrutiny it faces.

## The Rat Catcher

In the chapter titled "The Rat Catcher," the focus shifts to the internal dynamics and challenges faced by Facebook as it grapples with issues related to content moderation, political bias, and the spread of false information on its platform.

The chapter begins by delving into the controversy surrounding Facebook's Trending Topics feature and the role of human curators in shaping the news users saw. It highlights the power given to these curators to promote or suppress certain topics, leading to allegations of political bias. The revelation of this internal process stirs debate within the company and draws attention from conservative critics who accuse Facebook of suppressing conservative news.

As the 2016 U.S. presidential campaigns intensify, Facebook faces increasing polarization and the proliferation of false news sites. Employees raise concerns about the spread of misleading content, but their calls for action are met with resistance, with the company prioritizing growth and user engagement over addressing the issue.

The chapter also explores the partnership between Mark Zuckerberg and Sheryl Sandberg, emphasizing their complementary roles in running the company. Sandberg's influence and impact on Facebook's business strategies, including data mining and ad targeting, are highlighted. However, as Facebook faces scrutiny over its impact on youth safety and privacy, tensions arise during a meeting between Sandberg, Elliot Schrage, and a representative from child advocacy group Common Sense Media. The encounter showcases a clash between Facebook's agenda and the concerns of external stakeholders.

Furthermore, the chapter touches upon the expanding role of Sandberg in content moderation policies, a responsibility previously overlooked by Zuckerberg. Sandberg's involvement raises questions about the company's decision-making process and the potential influence of political considerations on content moderation.

Overall, "The Rat Catcher" chapter sheds light on the internal challenges Facebook faces in maintaining a neutral platform, addressing the spread of false information, and balancing its commitment to growth with responsible practices.


## The Warrant Canary

In Chapter, titled "The Warrant Canary," the focus shifts to Ned Moran, a security analyst at Facebook, and Alex Stamos, the newly hired head of security. Moran, known for his expertise in studying state-backed hackers, discovers a conversation between a Russian hacker and an American journalist on Facebook. This exchange between hackers and a journalist target is unprecedented, and Moran realizes the Russians are attempting to manipulate the U.S. elections.

As Moran investigates further, he uncovers the extent of the Russian hacking, including their creation of the "DCLeaks" page to disseminate stolen documents from the Democratic Party. Moran reports his findings to his superiors, but Facebook's top executives, including Mark Zuckerberg and Sheryl Sandberg, do not fully grasp the severity of the situation.

Meanwhile, Stamos, a renowned cybersecurity expert, joins Facebook and builds a dedicated security team. Stamos becomes a "warrant canary," someone known for raising alarm bells regarding privacy and security breaches. He advocates for prioritizing user safety and protection, drawing from his past experiences at Yahoo.

As the Russian hacking activity intensifies and Donald Trump openly calls on Russia to hack his opponent's emails, concerns grow within Facebook's security team. They realize that Facebook's algorithms can be manipulated by populists like Trump, and the company's inaction in addressing the Russian influence becomes a topic of internal debate.

Eventually, the threat intel team discovers that the Russian hackers have targeted the foundation run by George Soros. Facebook takes action by removing the DCLeaks page, but the abundance of divisive content continues to flood the platform leading up to the 2016 presidential election.

This chapter highlights the growing unease within Facebook's security team and their struggles to raise awareness about the Russian hacking activity. It sets the stage for the subsequent chapters, revealing the challenges Facebook faces in addressing the manipulation of its platform and the potential consequences for democracy.


## A Pretty Crazy Idea

Chapter, titled "A Pretty Crazy Idea," delves into the aftermath of the 2016 U.S. presidential election and Facebook's response to the growing criticism of its platform's role in spreading misinformation. The chapter highlights the company's efforts to address the accusations and the internal turmoil it caused.

Following Donald Trump's unexpected victory, Facebook's policy team gathers to discuss the implications and potential blame that could be placed on the company for the proliferation of false news during the election. Some employees privately believe that Facebook's lax approach to policing fake news contributed to Trump's win. Joel Kaplan, head of Facebook's Washington office, emphasizes the need for unity and warns that Facebook will face scrutiny.

Kaplan takes a proactive stance, creating an "administration pipeline" to explore potential hires with ties to Trump. Corey Lewandowski and Barry Bennett, former Trump campaign members, visit the office and pitch themselves as consultants. However, Kaplan decides against hiring them due to concerns about Lewandowski's controversial reputation.

Meanwhile, Mark Zuckerberg, Facebook's CEO, directs his executives to gather data to counter the narrative that false news played a significant role in Trump's victory. However, Facebook's lack of tracking false news makes it challenging to provide concrete numbers. Zuckerberg faces pressure to address the issue publicly and attends the Techonomy conference, where he dismisses the idea that fake news influenced the election. His remarks generate backlash, and Facebook employees express confusion and frustration internally.

Alex Stamos, head of security, discovers Zuckerberg's statement and realizes that the company's top executives are unaware of the alarming Russian activity his team has been investigating. Stamos requests a meeting with Zuckerberg and Sheryl Sandberg to address the issue.

This chapter highlights the internal conflicts within Facebook regarding its responsibility in the spread of misinformation and the company's initial response to the election fallout. The stage is set for a deeper examination of Facebook's role in the democratic process and the challenges it faces in combating disinformation on its platform.


## Company over Country

In the chapter titled "Company over Country," the focus is on Facebook's response to the discovery of Russian interference in the 2016 US presidential elections. The narrative highlights the internal struggles and decisions made within Facebook as they grappled with the extent of the Russian disinformation campaign and its implications. The chapter reveals the challenges faced by the company's security team, led by Alex Stamos, as they worked to uncover and analyze the activities of the Internet Research Agency (IRA), a Russian troll farm.

Despite the security team's findings, Facebook's top executives, including Mark Zuckerberg and Sheryl Sandberg, initially downplayed the severity of the situation and chose to prioritize the company's reputation over disclosing the full extent of Russian meddling. The team's discoveries of Russian ads and IRA-controlled accounts were kept under wraps, leading to contradictory statements made by Facebook's spokespeople and a lack of transparency with the public and Congress.

As pressure mounted, the security team, under Stamos's leadership, pushed for more action and disclosure. They prepared a security briefing for the Facebook board, which resulted in a heated meeting exposing the extent of Russian election interference. However, tensions within the company rose as Sandberg felt blindsided by the team's assessment and expressed frustration towards Stamos.

The chapter also explores Facebook's interactions with Congress and the media. The company's initial reluctance to share the content of the Russian-bought ads sparked criticism and demands for greater transparency. Eventually, Facebook provided a limited sample of the ads to Congress, but the redactions and the company's handling of the situation further fueled skepticism and mistrust.

The chapter concludes with the House Intelligence Committee's public presentation of the Russian ads and the subsequent hearings with representatives from Facebook, Twitter, and Google. Despite Facebook's promises to address the issue, its security team faced criticism and skepticism, with Stamos finding himself under scrutiny for the handling of the Russian disinformation campaign. The chapter ends with Stamos's departure from Facebook, symbolizing the company's prioritization of its own interests over the well-being of the country.

Overall, "Company over Country" sheds light on Facebook's internal struggles, conflicting interests, and the challenges it faced in addressing the Russian interference, ultimately highlighting the tensions between protecting the company's reputation and ensuring the integrity of democratic processes.

## Delete Facebook

In this chapter, titled "Delete Facebook," the narrative explores the infamous Cambridge Analytica scandal that rocked the social media giant. The story begins with the revelation that Cambridge Analytica, a political consulting firm funded by Trump supporter Robert Mercer and led by Stephen K. Bannon, had obtained profile information and data on millions of Facebook users without their consent. This breach of trust brought to light Facebook's long history of data privacy abuses.

The scandal raised urgent questions about Facebook's role in targeting voters during the 2016 US presidential election. Mark Zuckerberg, Facebook's CEO, found himself testifying before Congress, facing a hostile audience and intense public scrutiny. Protestors demanding the deletion of Facebook accounts gathered outside the hearing room, while inside, Zuckerberg faced tough questioning from senators regarding user privacy and the company's data handling practices.

The chapter delves into the origins of the Cambridge Analytica breach, tracing it back to the introduction of the "Open Graph" program in 2010. Facebook allowed outside app developers access to users' information, inadvertently enabling data harvesting and misuse. Despite warnings from employees like Sandy Parakilas, Facebook neglected to address the security and privacy vulnerabilities of the Open Graph system.

The backlash against Facebook and its COO, Sheryl Sandberg, intensified. Sandberg, known for her book "Lean In," faced criticism for allegedly blaming women themselves for their lack of success in the workplace. As the public backlash grew, Facebook's image as a force for good in society was overshadowed by negative stories and concerns about the platform's impact on privacy and democracy.

While Zuckerberg's congressional testimony was widely covered, the chapter highlights the knowledge gap and technological unfamiliarity of many lawmakers, which shifted the public's focus toward the incompetence of elected officials in addressing the issues at hand. Meanwhile, Facebook's well-funded lobbying efforts and resistance to privacy regulations demonstrated the company's commitment to protecting its lucrative business model.

Ultimately, despite the intense scrutiny and criticism, Zuckerberg's testimony had unintended consequences. Facebook's stock price rebounded, and Zuckerberg himself saw his wealth increase significantly. The chapter concludes with a sense of irony, as the public's attention shifted away from Facebook's practices and toward the deficiencies of Washington's understanding of technology.

Chapter "Delete Facebook," captures the pivotal moment when the Cambridge Analytica scandal exposed the company's disregard for user privacy and the challenges of regulating social media platforms in the face of political and public scrutiny.

## Think Before You Share

In this chapter, the focus shifts to the devastating impact of Facebook in Myanmar, particularly regarding the Rohingya genocide. The hearings involving Facebook extended beyond the Cambridge Analytica scandal, with lawmakers raising concerns about addiction, deceptive terms of service, election disinformation, and user protection. The most visceral example of the platform's harm emerged in Myanmar, where genocide unfolded in real time.

The chapter highlights the role Facebook played in exacerbating racial tensions in Myanmar. The spread of disinformation on the platform fueled hatred against the Rohingya minority. The Burmese military used Facebook as a tool to disseminate anti-Rohingya propaganda, inciting violence and promoting a false narrative. Human rights officials estimated that over 24,000 Rohingya were killed, and 700,000 fled to refugee camps in Bangladesh.

Despite repeated warnings, Facebook failed to address the situation adequately. The company's response was insufficient, with limited Burmese-speaking moderators and a lack of understanding of the local dynamics. Activists and NGOs attempted to communicate the severity of the situation to Facebook, but their messages went unanswered. The platform's content moderation policies proved inadequate, and its algorithms favored sensationalism and engagement, amplifying hate speech and dangerous content.

Facebook's negligence and inaction in Myanmar became increasingly evident. The company's focus on expanding internet access and user engagement overshadowed the potential harm caused by its platform. The chapter also discusses Facebook's controversial emotional contagion experiment, which demonstrated the platform's ability to influence users' emotions without their awareness.

As the Rohingya crisis worsened, human rights organizations sought assistance from Facebook in gathering evidence for international criminal prosecution. However, Facebook's legal team refused to cooperate, citing privacy concerns and potential lawsuits. They claimed that they would only cooperate if the United Nations created a mechanism to investigate human rights crimes, displaying a lack of knowledge about existing frameworks.

The chapter concludes by highlighting Facebook's failure to act responsibly in Myanmar and its repeated choices to prioritize engagement over the well-being and safety of users. Despite the platform's immense power to connect people, its impact on vulnerable communities and the spread of hate speech should serve as a reminder for users to think critically before sharing information on social media.

## The Wartime Leader

In the chapter titled "The Wartime Leader," the focus is on Mark Zuckerberg and his role as the leader of Facebook during challenging times. The chapter begins with Zuckerberg's defense of allowing controversial figures, such as Alex Jones of Infowars, to remain on the platform despite their dissemination of false information and hate speech. His stance on free expression and his belief in Facebook as a marketplace of ideas come under scrutiny, leading to widespread backlash.

The narrative then shifts to Yaël Eisenstat, a former CIA officer hired by Facebook to combat election interference. Eisenstat's efforts to address the spread of false and misleading information through political ads are repeatedly undermined and dismissed by Facebook executives. She encounters resistance when proposing fact-checking mechanisms and encounters a lack of support within the company.

The chapter further explores Facebook's handling of Russian election interference and its use of the opposition research firm Definers Public Affairs to discredit critics, including George Soros. The revelation of Facebook's association with Definers and the subsequent fallout expose the company's flawed public relations strategies and internal communication.

The chapter concludes with growing criticism of Sheryl Sandberg, Facebook's COO, and calls for her resignation. Despite the mounting pressure, Zuckerberg maintains trust in his leadership team and expresses confidence in their ability to navigate the crisis.

Overall, "The Wartime Leader" highlights the challenges Facebook faces in maintaining a balance between free expression and combating misinformation and election interference. It sheds light on the internal struggles, conflicting priorities, and criticisms faced by Zuckerberg and Sandberg as they grapple with the responsibilities of leadership in a rapidly evolving landscape.

## Coalition of the Willing

In this chapter, titled "Coalition of the Willing," the focus is on Mark Zuckerberg, the co-founder and CEO of Facebook, and the challenges he faced as the leader of the social media giant. The chapter begins with Zuckerberg's diplomatic efforts to defend Facebook and influence regulations amid rising concerns about violence and hate speech on the platform. However, his plans are interrupted by a scathing op-ed written by his former Harvard roommate, Chris Hughes, who criticizes Facebook's monopoly and calls for its breakup.

The chapter highlights Zuckerberg's reaction to the op-ed and his efforts to counter the narrative. It explores the growing discontent among early Facebook executives, including Hughes and former president Sean Parker, who express their concerns about the social network's impact and advocate for its dismantling. Political leaders, academics, and consumer activists also join the movement to break up Facebook and other tech giants.

Zuckerberg's decision to merge the messaging services of Facebook, Instagram, and WhatsApp is discussed, along with the backlash from Instagram and WhatsApp founders who had initially been promised independence. The chapter reveals tensions within the company regarding the privacy-focused direction and the potential security risks associated with the integration.

The narrative introduces law professors Tim Wu and Scott Hemphill, who view Facebook's acquisitions of Instagram and WhatsApp as part of a pattern to create a social media monopoly and eliminate competition. They draw parallels to the historical example of Standard Oil. The chapter explores the attempts by Facebook to stifle competitors, such as cutting off Twitter's Vine from a friend-finding feature.

The chapter concludes with the formation of a coalition against Facebook, comprising individuals such as Chris Hughes, Tim Wu, Roger McNamee, and Jim Steyer. They aim to establish a clear antitrust case against the company and hold discussions with state attorneys general, the Department of Justice, and the Federal Trade Commission (FTC) to advocate for the breakup of Facebook.

Overall, this chapter sheds light on the mounting criticism faced by Facebook, the internal challenges within the company, and the formation of a coalition of individuals seeking to address Facebook's monopolistic practices.

## Existential Threat

In Chapter "Existential Threat," the story delves into the challenging period for Sheryl Sandberg, the Chief Operating Officer of Facebook, as she faced intense scrutiny and pressure regarding privacy abuses and efforts to prevent disinformation during the 2020 elections. Sandberg's meeting with House Speaker Nancy Pelosi revealed a cool reception compared to their previous positive interaction, highlighting the growing tension between Facebook and lawmakers.

The chapter focuses on a manipulated video featuring Speaker Pelosi that went viral on Facebook, in which her words appeared slurred and inebriated. The video, which was later debunked as a doctored version, raised questions about Facebook's ability to tackle political misinformation. Pelosi and her staff were frustrated with Facebook's response and their failure to remove the video promptly, leading to strained relations between Pelosi and the company.

The chapter also explores Facebook's internal debates and discussions on controversial political content and the challenges of defining and addressing disinformation. Mark Zuckerberg's decision to keep the doctored video of Pelosi up, despite Sandberg's reservations, further eroded trust in the company and drew criticism from lawmakers.

Additionally, the chapter highlights Facebook's attempts to counter the growing calls for regulation and potential antitrust action. Nick Clegg, the former UK deputy prime minister and newly appointed Facebook executive, played a role in advocating for a more proactive political stance and proposing the creation of a trade group, "American Edge," to support domestic technology companies. However, Facebook faced challenges in gaining support from other tech giants for this initiative.

As the chapter concludes, multiple investigations into Facebook's practices were launched by the Federal Trade Commission, state attorneys general, and the House Judiciary Committee's antitrust subcommittee. The company's announcement of Libra, a blockchain currency system, drew further criticism and regulatory scrutiny. Amid the growing threats, Zuckerberg expressed a determination to fight back against any existential threats, particularly in response to presidential candidate Elizabeth Warren's promise to dismantle the company if elected.


## The Oval Interference

In the chapter titled "The Oval Interference," the focus is on the challenges and controversies faced by Facebook, particularly its CEO Mark Zuckerberg and COO Sheryl Sandberg. The chapter explores their responses to criticism and scrutiny regarding the platform's policies on political ads, misinformation, and hate speech. It highlights key events such as Clegg's speech on Facebook's political ad policy, the spread of misleading ads during the 2020 presidential campaign, and Zuckerberg's public address at Georgetown University defending free expression on the platform.

The chapter also delves into the growing backlash from civil rights leaders, lawmakers, and employees who criticized Facebook's approach to combating disinformation and protecting user rights. Sandberg's role in executing Zuckerberg's decisions and her attempts to dissociate herself from them are examined, along with her struggles with public perception and declining reputation.

Furthermore, the chapter touches on the increasing pressure faced by Facebook from external groups and individuals, such as the Coalition of the Willing and comedian Sacha Baron Cohen, who criticize the platform's handling of hate speech and its impact on society. It concludes with Zuckerberg's announcement of his philanthropic goals for the next decade and his determination to stand behind his positions publicly, even if it means facing backlash.

Overall, "The Oval Interference" chapter sheds light on the complex dynamics within Facebook, the challenges of balancing free expression and responsible content moderation, and the mounting criticism faced by the company and its top executives.

## Good for the World

In the chapter titled "Good for the World," the narrative explores Facebook's response to escalating issues surrounding misinformation, hate speech, and the organization of violent events on its platform. The chapter begins by highlighting Facebook's failure to address the Kenosha shooter's presence on the site, leading to right-wing groups rallying around him. The platform's vulnerabilities are exposed as fringe movements, militias, and conspiracy theorists exploit Facebook's group features to organize and recruit followers.

As the 2020 US presidential election approaches, Facebook faces increased pressure to combat misinformation and election interference. The company announces bans on QAnon and Holocaust misinformation, but fails to present a coherent change in policy, causing criticism from both employees and external organizations. Concerns about potential violence and unrest surrounding the election prompt Facebook to take emergency measures, including tweaking the News Feed algorithm and implementing temporary changes to promote reliable news sources.

On November 3, 2020, the election day, Facebook's election team remains vigilant in addressing misinformation and false narratives. However, rumors and baseless claims of election fraud spread rapidly, fueled by President Trump and his loyal supporters on the platform. Facebook's attempts to label false information prove ineffective, and the platform is overwhelmed by the volume of misinformation. In the aftermath of the election, Facebook's election team requests emergency measures, leading to temporary improvements in content quality, but these changes are later reversed due to concerns about user engagement.

The chapter also delves into the events of January 6, 2021, when rioters stormed the US Capitol. Facebook's security and policy teams were aware of the growing anger and extremist organizing on the platform, including discussions of violence, but were unable to prevent the violence from erupting. The executives grapple with how to respond to President Trump's posts and whether to ban him from the platform. Eventually, Zuckerberg decides to remove two of Trump's posts and imposes a 24-hour ban, extending it later and taking further action against pro-Trump groups.

The chapter concludes with Zuckerberg's announcement that the ban on Trump's accounts would be extended indefinitely, citing the risks of allowing the incitement of violence. However, Zuckerberg leaves the possibility open for future actions, reflecting the complex challenges Facebook faces in navigating political speech and maintaining a balance between free expression and preventing harm.

Overall, "Good for the World" highlights Facebook's struggles to address the negative consequences of its platform's reach, especially concerning the spread of misinformation, incitement of violence, and the potential influence on democratic processes. The chapter showcases the evolving response and internal debates within the company as it grapples with the broader implications of its role in shaping public discourse and safeguarding user safety.

## The Long Game

In the epilogue titled "The Long Game," the narrative explores Facebook's response to mounting challenges, including the establishment of the Facebook Oversight Board and the company's legal battles over antitrust issues. The chapter delves into the Oversight Board's early decisions, highlighting its role in adjudicating content removal cases and addressing Facebook's historical role in Myanmar.

The chapter also discusses Facebook's legal battles, particularly the federal and state antitrust lawsuits filed against the company. Facebook's extensive lobbying efforts and defense strategies are explored, including hiring former FTC officials and preparing potential antitrust suits against other companies like Apple. Zuckerberg's cautious approach to expressing his opinions on legal matters is noted, and Facebook's readiness to fight the lawsuits for the long term is emphasized.

The transition to the Biden administration prompts a significant overhaul of Facebook's lobbying operation in Washington, D.C. While some employees express frustration with the influence of Joel Kaplan during the Trump administration, he remains a trusted confidant of Zuckerberg. Sandberg's position within the company remains secure, and despite speculation, she is not interested in pursuing a position in the Biden administration.

During an earnings call, Zuckerberg announces plans to deemphasize political content on Facebook's News Feed, acknowledging the platform's failure to control harmful rhetoric. Sandberg focuses on the company's strong financial performance, highlighting revenue growth and increased user engagement.

The chapter concludes by highlighting the future possibilities and potential transformations that Facebook may undergo. With substantial cash reserves and a focus on innovative technologies like virtual reality and augmented reality, Facebook remains poised to expand into new lines of business. The chapter emphasizes Facebook's enduring success and its role in reshaping society, despite ongoing concerns about consumer privacy, safety, and the integrity of democratic systems.

Overall, "The Long Game" reflects on Facebook's ability to navigate challenges and adapt to new circumstances while maintaining its influence and profitability. It underscores the power and complexity of the platform, highlighting the dichotomy between its mission to connect people and its drive for profit, leaving open questions about its future trajectory.
