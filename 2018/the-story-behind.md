# The Story Behind
Emily Prokop

***

Summary of "The Story Behind" by Emily Prokop:

"The Story Behind," written by Emily Prokop, delves into the fascinating histories and origins of various everyday objects, inventions, and cultural phenomena. Spanning a wide range of topics, the book provides captivating insights into the stories behind things we often take for granted.

The book covers everything from common household items like toothbrushes, fire hydrants, and windshield wipers to significant inventions like gunpowder and the revolver. It also explores the intriguing histories of musicals, lullabies, and podcasts, shedding light on their evolution and impact on popular culture.

Emily Prokop's writing style is engaging and informative, making the book an enjoyable read for both curious minds and history enthusiasts. Each chapter offers a well-researched and concise account of the origins of various subjects, presented in an easy-to-follow narrative.

Through "The Story Behind," readers gain a deeper appreciation for the everyday items and concepts that shape our lives. Whether it's learning about the early uses of gunpowder or understanding the evolution of podcasting, the book provides a comprehensive and entertaining exploration of the stories that often go unnoticed in our daily lives.

Overall, "The Story Behind" is a captivating journey through history, revealing the intriguing and often surprising tales that lie behind the objects and phenomena we encounter in our modern world. Emily Prokop's work offers an enjoyable and enlightening reading experience for anyone curious about the origins of the things we interact with and experience on a daily basis.

***


## At the Office

### Bubble Wrap
The fascinating origin of Bubble Wrap takes us back to the post-World War II era when the GI Bill enabled returning soldiers to pursue education and buy homes, leading to a booming economy. As futuristic visions of space exploration and science-fiction movies influenced style choices, a shift from traditional decor to a more forward-looking approach emerged.

During this time, wallpaper evolved from a luxury affordable only by the wealthy to a more accessible commodity for everyone. In 1957, two inventors, Alfred W. Fielding and Marc Chavannes, sought to create a high-end plastic wallpaper with a unique textured design that would add a fun touch to walls. In Fielding's garage, they experimented with sealing two plastic sheets together, creating air pockets trapped inside, and added a paper backing to their creation.

Initially marketed as "Air Cap," their innovative wallpaper failed to gain popularity as expected. However, their remarkable material did not go to waste. Fielding and Chavannes founded the company Sealed Air to market their creation, but finding the right application for it proved challenging.

Enter the IBM 1401 variable-word-length computer, introduced in 1959. The need to safely ship and protect the new hardware during transportation became evident. Sealed Air's marketer, Frederick Bowers, saw an opportunity and pitched their material, now known as Bubble Wrap, to IBM. The solution was perfect, and Bubble Wrap found its purpose in safeguarding delicate computer components during shipping.

Over time, the manufacturing process improved, and machines were developed to create Bubble Wrap with evenly spaced bubbles, making it more efficient and effective. The material continued to evolve, becoming more environmentally friendly and durable for reuse. Nevertheless, companies like Amazon, dealing with massive quantities of shipments, constantly explore newer shipping materials due to the storage space occupied by large rolls and sheets of Bubble Wrap.

Beyond its practical utility, Bubble Wrap gained fame for its stress-relieving quality—popping the bubbles became a favorite pastime for many. A 1992 study even validated this stress relief effect, showing that subjects who popped Bubble Wrap felt more relaxed and alert afterward. Some theories suggest that this fascination stems from our primitive brain associating the sensation with crushing ticks or insects, while others argue that humans are naturally drawn to tactile sensations, making Bubble Wrap a convenient tool for releasing stress.

An interesting fun fact about Bubble Wrap is that Sealed Air licenses a calendar version of it, where each day is printed on a piece of paper underneath Bubble Wrap, allowing users to pop a bubble a day, making the mundane task of checking the date quite enjoyable.

### Comic Sans
Ah, Comic Sans—the font that divides the typographic world. Originating from the design of hand-drawn speech bubbles in comics, Comic Sans emerged as a playful and light-hearted alternative to more traditional fonts like Times New Roman and Helvetica. Created in 1994 by Vincent Connare during his time at Microsoft, the font was initially intended for use in a computer program called Microsoft Bob, designed for kids.

Microsoft Bob's cartoon-like interface required a font for speech bubbles, and Connare turned to his stack of comic books, finding inspiration in titles like Watchmen and The Dark Knight Returns. He crafted the letters in a way that would suit the software, but the original all-capital-letter font didn't fit well within the bubbles.

To address this issue, Connare added lowercase letters to the font, but by then, Microsoft Bob was already discarded. Nonetheless, Microsoft saw potential in Connare's creation and integrated it into their Movie Maker application, where it gained traction. Renamed "Comic Sans," the font was included in Windows 95 and Internet Explorer's system fonts.

However, Comic Sans also became one of the most criticized and mocked fonts, garnering disapproval from many typographers and designers. Despite its widespread usage, especially in educational settings and kids' activities, the font's informal and quirky appearance made it hard for some to take seriously.

Various instances of Comic Sans being used inappropriately or in serious contexts further fueled the font's negative reputation. From angry letters written by sports team owners to official presentations and even scientific findings being presented in Comic Sans, the font became synonymous with unprofessionalism and lack of design awareness.

Despite the backlash, Comic Sans found some supporters who defended its legibility, especially for dyslexic readers who might find fonts resembling handwriting easier to read. Nevertheless, studies on this claim have yielded mixed results.

Over time, Comic Sans became deeply ingrained in popular culture, showing up in memes, parodies, and even a reference in Weird Al Yankovic's song "Tacky," where he humorously sings about printing his resume in Comic Sans.

To manage the Comic Sans dilemma, design experts advocate for using the font appropriately in settings where its light-hearted and informal appearance suits the context. Ultimately, like any design choice, using Comic Sans wisely is essential to avoid its unintended negative connotations.

### Correction Fluid
In the days before autocorrect and backspace keys, typewriters and handwritten papers were the norm. Bette Nesmith Graham, a single mother working as an executive secretary in 1951, faced a recurring problem in her typing—mistakes and errors that were challenging to correct without making a mess. Erasers for pencil mistakes were available, but for formal documents, they were impractical.

Inspiration struck Graham when she saw painters covering their mistakes with additional layers of paint instead of redoing the entire artwork. This observation led her to experiment with white tempera paint in her kitchen due to its fast-drying and long-lasting properties. Graham began using her creation, which she called "Mistake Out," to correct her typing errors at work, and soon her colleagues wanted to try it too.

Seeing the potential in her invention, especially with the increasing use of electric typewriters, which made people more prone to errors due to their higher finger sensitivity compared to manual typewriters, Graham's "Mistake Out" gained popularity. With the help of her son's chemistry teacher, she refined the formula, creating what would become known as "Liquid Paper."

Continuing to work as a secretary, Graham invested time in learning business management and marketing to promote her product. However, she faced an ironic twist when she was fired from her job for making a typing mistake on her company's letter instead of the bank's name.

Nevertheless, the success of Liquid Paper was unstoppable. Graham patented the formula and pitched it to IBM, though they initially turned it down. The following year, Graham's factory was producing ten thousand bottles of Liquid Paper daily, and businesses began realizing the value of the product for correcting errors on paper documents.

In 1966, a competitor called "Wite-Out" hit the market, but Liquid Paper remained popular for fixing mistakes on pen-and-paper documents, even with the rise of computers. In 1979, just a year before her passing, Graham sold her company to Gillette, solidifying her legacy as the inventor of correction fluid.

### The Paper Clip
Before the paper clip's ingenious invention, various methods were used to keep papers together, including tying them with string, using wax or glue, or even sewing pages together with a needle and thread. While straight iron pins gained popularity in the nineteenth century, they often caused accidental pricks and damaged the papers.

The transition from iron to steel as a more malleable yet strong material during the mid-1800s prompted the search for a better paper fastener that wouldn't rust. Although several designs and

 patents were filed during this period, Johan Vaaler, a Norwegian inventor, is often credited with creating the first recognizable paper clip in 1899. His invention featured a single piece of wire bent into a triangular shape, with one end serving as the clasp.

However, Vaaler's design didn't immediately gain traction, and various other paper clip designs emerged around the same time. One notable design was the "Gem Paper Clip," patented in 1867 by Samuel B. Fay, which is still commonly used today.

The Gem Paper Clip's success can be attributed to its simple design, ease of use, and efficiency in holding papers together securely. Fay's patent expired in 1899, the same year Vaaler patented his design, leading to an open market for paper clip production.

Over time, the Gem Paper Clip became the quintessential paper clip design, enduring decades of technological advancements and remaining relatively unchanged. It's a remarkable testament to the strength of simple yet effective design solutions that continue to serve us well to this day.

### The Pink Slip
The origin of the term "pink slip" in the context of job termination is a bit elusive, with no definitive source identified. Some theories suggest that the term originated from the practice of using pink-colored slips of paper for termination notices. However, concrete evidence to support this claim remains scarce.

The use of pink slips in employment termination documents became more prevalent in the United States, with the color itself symbolizing a sense of urgency and importance. When an employee received a pink slip, it meant their job was at an end, and they were being dismissed.

The phrase "pink slip" became well-known in the US lexicon and was used colloquially to refer to a termination notice or the act of firing someone. During periods of economic downturn or high unemployment rates, the fear of receiving a pink slip intensified, as job security became increasingly precarious.

Interestingly, the term "Pink Slip Parties" emerged during a time of economic recession in the early 2000s. These parties were gatherings where employers would inform their employees of their job loss by giving them pink slips, but they would also offer opportunities for networking and job hunting among attendees.

Outside of the employment context, California uses the term "pink slip" to refer to a vehicle's title. This tradition started in the 1950s when car titles were printed on pink-colored paper, distinguishing them from other documents.

Overall, the history and etymology of the term "pink slip" have become intertwined with employment and job security, reflecting the uncertainty and challenges faced by employees throughout history.

## Fashion
### Buttons
Buttons, those small and unassuming fasteners we use every day, have a rich history that spans thousands of years. While they now serve as practical closures on clothing, buttons were initially more decorative in nature. The early origins of buttons can be traced back to around 2000 BC, with the Romans being credited as among the first to use buttons as clothing fasteners by looping fabric over them. Another precursor to modern buttons was the fibula, an ancient fastener akin to today's safety pins.

As fashion evolved and tailored silhouettes gained popularity, buttons transitioned from decorative elements to functional fasteners. They allowed dressmakers to create form-fitting garments that accentuated the waist and eliminated the need for sewn-together sleeves that had to be cut open at night. Buttons became a means to not only fasten clothes securely but also to enhance the overall aesthetics of garments.

Throughout history, buttons were made from a myriad of materials. British soldiers returning from the Crusades introduced intricately painted buttons made by the Turks and Mongols to the western world. Inspired by these exotic buttons, the upper class adorned their gowns with their own lavish versions. As time went on, button materials were associated with different social classes, with the wealthy flaunting precious metals and gems, while the lower class had to make do with wood or cloth buttons.

The eighteenth century is considered the Golden Age of buttons, as they became more intricate and larger, often featuring carvings of ancient myths and folklore characters. Queen Victoria's use of jet buttons with her monogram VR in mourning for Prince Albert's death popularized "Mourning Buttons." The Victorian era also saw a trend of lithographs and portraits of high-profile figures and landmarks being stamped onto metal buttons.

Buttons were ubiquitous in fashion, adorning various articles of clothing, including shoes, which required a specialized tool called a button hook to fasten them. Four-hole buttons, although less decorative, became the most common due to their practicality and secure hold on clothing.

The advent of the zipper in 1913 led to a decline in button sales, but buttons found renewed use during World War II. Military buttons were often designed with hidden compasses, allowing pilots to navigate in case of emergencies. Today, military buttons with their unique insignia and stampings remain highly sought after by button collectors.

While buttons may have shifted from being primarily decorative to functional, their journey through history showcases their versatility and enduring appeal. From ancient embellishments to modern fasteners, buttons have not only held our clothes together but also served as artistic expressions of fashion and style. As fashion continues to evolve, buttons will undoubtedly remain an essential and intriguing part of our wardrobe, preserving a connection to the past while adapting to the needs of the present.

### Mustaches
Throughout history, mustaches have enjoyed a rollercoaster ride of popularity, going in and out of fashion like the changing tides. One of the early iconic mustache styles, known as the "Van Dyck," gained fame from portraits by Sir Anthony Van Dyck, featuring King Charles I sporting a pointed goatee and handlebar mustache. However, facial hair faced a decline in popularity toward the end of the 17th century when Tsar Peter of Russia mandated clean-shaven faces, even imposing a beard tax to discourage facial hair.

The Victorian era witnessed a revival of mustaches, becoming so popular that a unique utensil was invented: a spoon with a mustache-shaped cutout to protect the facial hair from food. Unfortunately, the mustache's allure faded again during the Depression, with job seekers being advised against showing up with mustaches due to the perceived unkempt impression it conveyed.

World War II further impacted mustache trends, with clean-shaven soldiers setting the style. The once-famous toothbrush mustache, associated with Adolf Hitler, fell out of favor and never regained popularity despite the love for Charlie Chaplin's similar look.

Mustache styles, both classic and iconic, have graced the faces of numerous notable figures. From Teddy Roosevelt's walrus mustache to Freddie Mercury, Burt Reynolds, and Tom Selleck's iconic chevron mustaches, each had its place in the annals of facial hair history.

Interestingly, the Fu Manchu mustache, extending to the chin, derived its name from the character Dr. Fu Manchu, frequently portrayed as an evil genius in various forms of media in the first half of the twentieth century.

Baseball, too, witnessed the rise and fall of the mustache. Satchel Paige was one of the last major-league baseball players to sport a mustache during a game in the 1940s. Decades later, Reggie Jackson's mustache led to a memorable incident during spring training with the Oakland A's, inspiring the infamous mustache-growing challenge among teammates.

In more recent times, Movember emerged as a mustache-focused fundraising campaign to raise awareness for prostate cancer, testicular cancer, and men's mental health. The initiative, born from two friends' conversation in a Melbourne bar, has since raised over $730 million Australian dollars for various causes.

The mustache's journey through history showcases its ever-changing allure and significance in both fashion and social causes. As facial hair trends continue to evolve, one thing remains certain: the mustache's ability to leave an indelible mark on cultural and social landscapes will persist, making it a timeless and versatile symbol of expression and activism.

### Nail Polish
Nail polish, a timeless cosmetic adornment, can trace its roots back to ancient civilizations. As early as 3200 BC, Babylonian soldiers donned nail stains as part of their war paint to intimidate enemies. In China, around 3000 BC, a mixture of beeswax, egg white, and dyes was used to color-code people based on their societal rank, with gold and silver reserved for the highest classes.

Throughout history, nail decoration became a status symbol, signifying a life of luxury and exemption from manual labor for those in the upper classes. However, it wasn't until Cleopatra in the first century BC that painting nails became widely popular. The use of henna for hand designs also became a cherished ritual, popularized by Queen Nefertiti and others.

Fast forward to the late 1800s, and salons in Paris offered nail care services using creams, oils, and powders to shine and pamper the nails. The term "polish" originated during this time, signifying the act of shining nails. In 1878, Mary Cobb established the first manicure parlor in America, catering to women seeking a touch of luxury.

The pivotal breakthrough for modern nail polish came from an unexpected source: nitrocellulose, originally developed as an explosive in the 1830s. The mixture of cellulose and nitric acid produced lacquers that hardened, laying the foundation for nail polish. The Charles Revson company, with the innovative idea of French makeup artist Michelle Ménard, capitalized on this discovery and began manufacturing nail polish in the 1920s, eventually becoming the renowned brand Revlon.

Over the years, nail polish trends have evolved with fashion. World War I led to bolder choices for women, including vivid nail colors and the iconic "moon manicure" style. Acrylic nails were introduced in the 1950s as a solution for those desiring fashionable long nails.

The French manicure, featuring a natural-looking base with a white-tipped finish, has two claimed inventors. Max Factor offered it to Parisian women in the 1930s for a clean and elegant look, while Hollywood makeup artist Jeff Pink revolutionized the concept in 1975 to cater to actresses and runway models with ever-changing outfits.

Today, nail polish offers an endless array of shades and nail art possibilities. New trends emerge each year, often popularized by celebrities. From classic reds to avant-garde designs, nail polish continues to be an expression of beauty and style, captivating women worldwide.

### Pockets
The history of pockets offers an intriguing glimpse into the evolution of fashion and functionality. In the seventeenth century, men boasted pouches sewn into their attire, providing convenient storage for their belongings. On the other hand, women's pockets were hidden beneath layers of skirts, tied with ribbons, and often required revealing a little skin to access.

Historically, women carried various essentials in these concealed pouches, ranging from pin cushions and sewing supplies to snuff boxes and smelling-salts bottles, catering to their needs in a world where they were seldom entrusted with managing finances.

However, as Marie Antoinette popularized slimmer and more Grecian-cut dresses, the fashion of big-skirts-and-dresses began to fade, leading to the decline of pockets in favor of more streamlined silhouettes. The introduction of outside purses provided an alternative means of carrying belongings, and the trend has persisted to this day.

Pockets, once widely prevalent, also became a target for pickpockets as clothes tailored with them increased. These nimble-fingered thieves were charmingly portrayed in popular culture, from Charles Dickens' Artful Dodger to the modern-day illusion master Apollo Robbins, who famously outwitted Jimmy Carter's Secret Service detail.

Modern pickpocketing techniques have evolved, relying on diversion and sleight of hand. However, with mandatory schooling and increased awareness, pickpocketing has seen a decline in America.

In recent times, the lack of functional pockets in women's clothing has become a point of contention. Internet memes humorously highlight the excitement of women when they find a dress with pockets. Yet, many women encounter fake or sewn-closed pockets in their clothing, reflecting the reluctance to add bulk to the hips, a trend initiated by Marie Antoinette.

Despite this, technological advancements and the demand for more pocket space have led to innovative designs. Dresses with sewn-in pockets have garnered immense popularity, as women embrace the practicality and convenience they offer. Still, the battle for more functional pockets continues, with many hoping for the resurgence of cargo pants.

While the fashion industry deliberates over the inclusion of pockets, purse makers have thrived, benefiting from women's need for additional storage. Yet, the charm of functional pockets remains, and women eagerly champion the cause for more pocket-friendly clothing.

### Tattoos
The art of tattooing has been an ancient tradition, dating back over 5,300 years when the mummified Otzi the Iceman was discovered adorned with fifty-seven tattoos, believed to be medicinal in nature. Throughout history, tattoos have held cultural significance across the globe, from Egypt to Greece, China to Polynesia.

The term "tattoo" itself finds its origin in the Tahitian word "tatau," meaning to hit or strike. European exposure to tattooing began in 1769 after Captain James Cook's expedition. Although Christian missionaries attempted to suppress the practice, it continued to thrive and even gained popularity as a symbol of good luck, especially among sailors and workers in high-risk occupations.

Sailors, in particular, have a long-standing association with tattoos, using them as talismans of protection during long voyages. Nautical stars and compass roses served as symbols of finding one's way home, while swallows indicated the distance traveled at sea. Other tattoos, such as pigs and roosters on the feet, were meant to bring luck during shipwrecks.

Sailor Jerry, also known as Norman Collins, made significant contributions to the world of tattoos, especially those associated with the sea. Influenced by Eastern art and techniques, he revolutionized tattooing in Hawaii, pioneering the use of single-use needles and autoclaves for sterilization.

Before the advent of modern tattoo machines, various cultures relied on rudimentary tools to create intricate designs. Native Americans, Polynesians, and Hawaiians used sharpened bones or rocks, while Samoans employed bamboo cutting tools with ink-filled combs to create their bold and large-scale tattoos.

The invention of the electric pen by Thomas Edison in 1876 marked a significant moment in tattoo history. Although it did not catch on for its original purpose, tattoo artist Samuel F. O'Reilly saw its potential as a faster and more efficient way to tattoo the skin. He adapted the device, creating the first electric tattoo machine, which has undergone little change since its inception.

From ancient medicinal tattoos to modern artistic expressions, the art of tattooing continues to evolve and captivate people across the world. As tattoo artists blend tradition with innovation, the legacy of tattoos remains an enduring form of personal expression and cultural significance.

### The T-Shirt
The T-shirt, now a ubiquitous wardrobe staple, has a fascinating history that traces back to its origins as a practical undergarment. The union suit, a one-piece red flannel outfit with a butt flap, provided warmth to workers in the late 1800s. As temperatures rose, workers began cutting the union suits at the waist, giving rise to the top half of the garment—the T-shirt.

The turn of the century saw the introduction of a neck hole that did not require buttons and allowed the garment to snap back without stretching. In 1905, the US Navy adopted plain white cotton undershirts as part of its uniform, and the undershirt became official attire for the US Army during World War I. The term "T-shirt" made its literary debut in F. Scott Fitzgerald's novel, This Side of Paradise.

The T-shirt's popularity soared when high-school athletes wore them to prevent chafing caused by football padding. Marlon Brando's portrayal of Stanley Kowalski in A Streetcar Named Desire in 1951 cemented the T-shirt's status as outerwear. Soon, businesses and brands seized on the blank canvas offered by T-shirts to showcase their logos.

Throughout the years, T-shirts have been the canvas for various trends, from Che Guevara's face symbolizing rebellion to Katharine Hamnett's "CHOOSE LIFE" slogan immortalized in Wham!'s music video. However, with innovation came extravagant price tags, with Kanye West's Hip-Hop T-Shirt priced at $120 and the Plain T-Shirt at $90.

T-shirts have also played a surprising role in humanitarian efforts. Merchandise made for losing teams in major sporting events is collected by World Vision and distributed to people in disaster areas and impoverished nations.

While T-shirts have become a symbol of irony for hipsters, second-hand clothing donations from Western countries have had complex effects on developing nations. These donations, while providing street sellers with affordable merchandise, have adversely affected local manufacturers and artisans.

The T-shirt, once a humble undergarment, has transformed into a fashion icon with a rich history and diverse cultural significance. Its evolution continues, driven by fashion trends, artistic expressions, and social impact.


## Food

### Bubble Gum
The story of bubble gum takes us back to the early 1900s, where Frank Fleer, the founder of the Fleer gum company in Philadelphia, was determined to create the perfect gum for blowing bubbles. However, his attempts were thwarted by its extreme stickiness, making it a tough sell in the market. Walter Diemer, a young accountant working for Fleer, saw an opportunity and began experimenting with new gum recipes in his spare time.

At the age of twenty-three, Diemer struck gold when he developed a less sticky and more stretchable gum that was perfect for bubble-blowing. Excited by his discovery, he brought a five-pound sample to a local grocery store, and it sold out on the same day. Fleer recognized the potential and named the new bubble gum "Dubble Bubble," which became the first commercially-sold bubble gum.

Around the same time, in 1938, four brothers started Topps Chewing Gum in Brooklyn. They introduced their own bubble gum, Bazooka, named after a musical instrument, not the weapon. The gum came wrapped in a comic strip featuring a character called Bazooka Joe, known for his eye-patch and cheesy jokes.

In 1952, Topps replaced the comics with baseball cards featuring Major League Baseball players. The cards became wildly popular among kids, leading Topps to focus exclusively on producing sports cards in the following years. Although Bazooka gum became a separate entity from the cards, it continued to include a stick of gum in each pack.

Over time, Bazooka Joe underwent style changes, and the comics eventually disappeared altogether in 2012 when the brand was rebranded. The gum's packaging featured word games, puzzles, and codes to keep consumers engaged.

Despite its popularity, gum sales have declined in recent decades due to concerns over sugar consumption and its link to cavities. However, research has shown that gum chewing can have cognitive benefits, such as improving test scores and enhancing focus.

For those curious about the rumor that swallowed gum stays in the stomach for seven years, it's a myth. While gum isn't easily digested like other foods, it eventually passes through the digestive system and is eliminated from the body.

Interestingly, if you're a gum-loving fidgeter planning to visit Singapore, you might need to find a new vice, as the country has banned gum for more than two decades, except for cases with a prescription.

### Chocolate Chip Cookies
The origin of chocolate chip cookies is a tale often told, but the true story of their creation unveils a more deliberate and skilled baker behind their invention. Contrary to popular belief, the accidental addition of chocolate chips was not the catalyst for this delectable treat. Ruth Wakefield, a well-versed dietitian and food lecturer, owned the Toll House Inn in Massachusetts alongside her husband, Kenneth, where they upheld traditions of serving colonial dishes.

Wakefield's approach to her culinary craft was far from haphazard. Known for her meticulousness, she trained her staff rigorously, and the restaurant's waitresses adhered to a seven-page manual, ensuring exceptional service to the patrons. Ruth Wakefield's reputation as a competent and disciplined chef dispels the notion of her accidentally adding chocolate chips to her cookies.

In the 1930s, while preparing cookies as an accompaniment to an ice-cream dessert, Wakefield decided to deviate from her usual butterscotch nut cookies and purposefully incorporated chocolate chips into the batter. The outcome was an instant hit, leading her to publish the recipe in newspapers and feature it on a popular radio program.

The chocolate chip cookie's fame spread like wildfire, and Wakefield even collaborated with Nestle, providing her recipe for free in exchange for unlimited Nestle chocolate. The cookies became an American favorite, gaining even more popularity during World War II, when they were sent overseas to soldiers as a symbol of support and comfort from home.

Despite its enduring popularity, the Toll House Inn met a tragic end in 1984 when it burned down, leaving behind only a historical marker at the site. Today, chocolate chip cookies stand as a classic part of culinary Americana, beloved by people of all ages and cherished for their simple yet timeless charm.

### Dr Pepper
The story of Dr Pepper begins with Charles Alderton, a young pharmacist working in Waco, Texas, in 1885. While experimenting with flavored syrups for the soda fountain at Morrison's Old Corner Drug Store, Alderton stumbled upon a concoction that pleased customers. Originally known as the Waco, the drink was eventually named Dr Pepper by the store owner, Wade Morrison, after various unverified stories about its origin.

The soft drink's popularity soared, leading Alderton and Morrison to sell the syrup to other pharmacies in the area. However, the demand soon outpaced their supply, prompting the suggestion that beverage chemist Robert S. Lazenby further develop the beverage.

In 1904, Dr Pepper made its debut at the World's Fair, alongside other iconic treats like hot dogs on buns and ice cream cones. The 1920s and 1930s saw Dr Pepper's advertising campaigns emphasizing the drink's potential energy-boosting properties, with slogans encouraging people to "Drink a bite to eat at 10, 2, and 4."

Over the years, Dr Pepper underwent several changes, including dropping the period after "Doctor" in its logo to avoid confusion with "Dr: Pepper." Its popularity was further boosted when it was featured on Dick Clark's American Bandstand in the 1950s.

While the true origin of the name Dr Pepper remains a mystery, a popular theory suggests that John W. Davis, a former oil businessman, spread the story that Morrison named the drink after the father of a girl he loved but who ultimately broke his heart.

The recipe for Dr Pepper remains a closely guarded secret, known only to three senior employees. In 2009, a manuscript collector stumbled upon an old notebook with a partially legible recipe titled "D Peppers Pepsin Bitter," which some speculated could be the original formula. However, Dr Pepper's spokesperson clarified that it bore little resemblance to the actual recipe and might have been a digestive made up of flavored syrups and mandrake root.

Dr Pepper's unique position as a non-cola allowed it to be sold at restaurants serving either Coke or Pepsi, giving it broader market reach. Despite attempts by Coca-Cola to introduce a similar product called Mr. PiBB in 1972, Dr Pepper's sales remained strong, with consumers craving its distinct taste even more.

In the 1990s, Cadbury/Schweppes acquired Dr Pepper and 7UP, eventually forming the Dr Pepper Snapple Group after acquiring other brands like Snapple and RC Cola. Today, Dr Pepper remains a beloved and iconic soft drink, cherished for its unique flavor and enduring legacy in the beverage industry.

### The Lollipop
The concept of placing candy on a stick dates back thousands of years to ancient China, Arabia, and Egypt, where fruits and nuts were coated in honey and affixed to wooden sticks for easier consumption. As sugar became more accessible in seventeenth-century England, street vendors in London began selling soft candy or meat on sticks, giving rise to the term "lolly pop," with "lolly" meaning tongue and "pop" referring to the act of slapping.

The true origin of the modern lollipop is shrouded in several competing stories. One version attributes the invention to George Smith of the Bradley Smith Candy Company in New Haven, Connecticut, who named it after his favorite racehorse, Lolly Pop. Another tale involves the McAviney Candy Company, also from New Haven, where candy-stirring sticks became the prototype for lollipops. Regardless of the origin, George Smith secured a patent for lollipops in 1931, although it proved challenging to enforce due to the term's widespread use.

In 1908, a company from Racine, Wisconsin, developed the first automated machine capable of placing hard candy on sticks, further popularizing lollipops. However, the term "lollipop" itself had already appeared in written records in the late eighteenth century, suggesting that the name was not entirely original.

During the Great Depression, lollipops experienced a decline in demand, but the resurgence came when child star Shirley Temple sang "On the Good Ship Lollipop" in the movie "Bright Eyes" in 1934. The candy's popularity continued to grow, and it became an icon in pop culture, featuring in movies, songs, and television shows like "The Wizard of Oz" and "Kojak."

In the late 1950s, Spanish entrepreneur Enric Bernat created a bonbon on a stick, initially named "GOL." Renamed Chupa Chups (meaning "to suck" in Spanish), the product received a logo designed by the renowned artist Salvador Dalí, which remains recognizable to this day.

The enduring Tootsie Pop also holds a special place in lollipop lore, with rumors suggesting that finding a specific wrapper with an Indian and shooting stars and mailing it to the Tootsie Roll company could win you more Tootsie Pops—a claim that Tootsie Roll clarifies as false. However, the Tootsie Roll company does invite fans to count the number of licks it takes to reach the center of a Tootsie Pop (without biting) and claim a Clean Stick award from the beloved Mr. Owl, known from classic commercials.

From ancient origins to modern-day delights, the lollipop's journey remains a sweet and enduring treat enjoyed by people of all ages, celebrated for its simple yet delightful charm.

### Peanut Butter
Peanut butter, despite its name, is not derived from nuts but rather from legumes. This distinction allows some individuals with tree-nut allergies to still consume peanuts without adverse reactions. Its origins can be traced back to the eighteenth century, with evidence suggesting that the Aztecs may have mashed peanuts to create a paste.

In 1895, Dr. John Harvey Kellogg, the creator of Kellogg's Corn Flakes, patented a process for making peanut butter and marketed it as a protein substitute for those with chewing difficulties. He introduced peanut butter to patients at the Battle Creek Sanitarium in Michigan, where it gained popularity.

Although often credited with inventing peanut butter, Dr. George Washington Carver was not the first to produce the peanut spread. However, his extensive work with peanuts and promotion of their versatility contributed to its popularity during the 1910s and '20s.

The true rise of peanut butter came during World War II when meat and butter were scarce, and rationing was in effect. Peanut butter served as a cheap and accessible substitute for protein, becoming a staple in the diets of soldiers and civilians alike. The combination of peanut butter and jelly, born out of military rations, became a beloved and enduring classic, especially among children during the Baby Boom era.

Jif, which entered the market in 1958, revolutionized peanut butter by using more vegetable oils like soy or canola to stabilize the product. Consumer Reports later revealed that Jif included half a cup of cooking fat per jar, leading the FDA to propose that peanut butter must consist of at least 95 percent peanuts. This sparked a legal battle known as the "Twelve-Year Peanut Butter Case," ultimately settling on the 90 percent peanuts standard.

Across the pond in the UK, peanut butter doesn't enjoy the same level of popularity as in the United States. Britons often find the texture of peanut butter off-putting, and mixing it with jam is frowned upon. In contrast, in the US, peanut butter and jelly sandwiches are a beloved favorite, with strawberry jam and smooth peanut butter being the most popular choices.

Peanut butter has found its way into the eating habits of famous figures, with both former President Bill Clinton and Elvis Presley favoring peanut butter and banana sandwiches. Interestingly, two US presidents, Thomas Jefferson and Jimmy Carter, were peanut farmers.

Whether spread on bread, used as an ingredient in various dishes, or enjoyed as a simple sandwich, peanut butter remains a versatile and cherished treat loved by people around the world for its rich flavor and nostalgic appeal.

### Pretzels
The history of pretzels is a fascinating journey filled with twisted tales, and while there isn't one concrete origin story, several intriguing narratives have emerged.

One of the most common stories dates back to 610 AD when an Italian monk sought to keep his catechism students engaged during prayer. He rolled out dough and crossed the ends, mimicking the position of their arms. He named his creation "Pretiola," which means "little reward" in Latin, or alternatively "Bracellae," which means "little arms." The word "Brach" or "Brace" in Latin, also related to arms, can be seen in other terms like "bracelet" and "embrace."

The popularity of pretzels spread throughout Europe during the Middle Ages, and they were commonly given to the poor as a nourishing and affordable food. Associated with Lent and Easter, pretzels were baked and hidden for children to find, alongside the more familiar hard-boiled eggs.

While invented by an Italian, pretzels have become closely associated with Germany, and there's a distinction between traditional pretzels and German pretzels. One story suggests that German pretzels were born accidentally in 1839 when a baker mistakenly brushed them with a sodium hydroxide solution used to clean bakery equipment. The resulting crispy brown crust and salty taste were a hit with guests, making it a new German favorite.

Another accidental innovation occurred in 1600 when a baking apprentice in Pennsylvania overcooked a batch, creating the first hard pretzels. Angry at first, his boss tasted the crunchy pretzels and found them delicious, leading to the popularity of this new variation.

Beyond their origin stories, pretzels hold religious symbolism, with the knot and the three holes representing the Holy Trinity. In various cultures, they symbolize good luck, prosperity, and a long life.

Pretzels continue to be beloved worldwide, with different countries contributing their own lore. In Germany, children wear pretzel necklaces on New Year's Day, and in Switzerland, newlyweds break a lucky pretzel similar to a wishbone. Austria's pretzel lore involves monks who alerted the city to Ottoman Turks' underground tunneling, and the Viennese King rewarded the bakers with their coat of arms—a lion holding a shield shaped like a pretzel.

Pretzels also made their way to America, possibly on the Mayflower, and they have remained one of the most popular snack foods. Their cultural impact is evident in pop culture references, such as the famous line from Seinfeld, "These pretzels are making me thirsty!" Even former President George W. Bush experienced a memorable pretzel moment when he choked on one and fainted, later making light of the incident in a speech.

Overall, pretzels have come a long way from their humble origins, becoming a beloved treat with a rich history and a wide array of cultural significance.

### Salt Water Taffy
Salt water taffy, a beloved souvenir of Atlantic City, has a fascinating origin story with a touch of humor. Legend has it that in the 1800s, a candy stand owned by David Bradley on the Atlantic City shore was flooded by a storm. As he cleaned up the debris, a little girl asked to buy some taffy. Bradley, in a sarcastic tone, told her he would gladly sell her some "salt water taffy."

The details get a bit hazy from there, as different versions of the story emerge. It's said that either the girl's mother, Bradley's mother, or Bradley's sister overheard the conversation and thought the name was clever for marketing purposes. From then on, taffy sold at Bradley's stand became known as salt water taffy. Interestingly, Bradley never trademarked the name, allowing its popularity to grow.

Joseph F. Fralinger, a versatile entrepreneur who had tried various ventures with little success, recognized the appeal of salt water taffy to tourists. In 1884, he opened a taffy shop and used decorative oyster boxes to package a pound of finger-sized taffy for visitors to take home as souvenirs. His original flavors were molasses, chocolate, and vanilla. Fralinger acknowledged that Bradley's candy stand had also used the term "salt water taffy," along with other names like Ocean Wave Taffy and Sea Foam Taffy.

Another key figure in the history of salt water taffy was Enoch James, a candy company worker who claimed to have been making the treat for years. James' taffy had a less sticky texture, making it easier to unwrap. He shaped his taffy into round pieces, which allowed people to enjoy a whole piece at once. James revolutionized the taffy-making process by using copper kettles and pulling the taffy over a hook multiple times, creating a lighter product. He also invented several taffy and candy-making machines that are still in use today.

By the 1920s, "salt water taffy" had become a popular term, though it remained an unregistered trademark. A man named John R. Edmiston tried to gain control of the term by filing a trademark, but James contested it, leading the US Patent Office to reject Edmiston's ownership claim. As a result, the delightful treat remained a beloved symbol of Atlantic City, enjoyed by visitors and locals alike.

### Sliced Bread
The invention of sliced bread revolutionized the way people consumed bread and became a significant milestone in culinary history. Before sliced bread came into existence, bread had been a staple in human diets for thousands of years. It played a crucial role in the development of settled communities, as it provided an efficient way to feed large numbers of people.

The credit for inventing sliced bread goes to Otto Rohwedder, an Iowa native who had a vision for pre-sliced bread. He was so passionate about his idea that he sold his jewelry stores and returned to Iowa to work on his prototype. After facing setbacks, including a factory fire that destroyed his machines and blueprints, Rohwedder persevered and continued his efforts.

Coincidentally, the toaster was introduced before sliced bread became popular. The availability of pre-sliced bread increased with Rohwedder's invention, but there was a problem—sliced bread tended to go stale quickly once the package was opened. Rohwedder worked to find a solution and eventually started wrapping the sliced bread in waxed paper and cellophane to keep the slices fresh and intact.

His innovative bread-slicing machine, equipped with a wrapping mechanism, quickly gained popularity among bakeries. In a short time, pre-sliced bread outsold unsliced loaves, and the demand for Rohwedder's machines soared.

During World War II, due to rationing and scarcity of steel, pre-sliced bread was temporarily subjected to rationing as well. This limitation frustrated Americans, who had grown accustomed to the convenience of sliced bread. After a two-month period, the ration on sliced bread was lifted, and the phrase "greatest thing since sliced bread" gained traction as people recognized the luxury of readily available sliced loaves.

With the advent of sliced bread, people embraced its convenience and versatility. It became a household staple, and the phrase "greatest thing since sliced bread" has since become a popular expression to describe something highly regarded and revolutionary. As sliced bread became a cherished part of daily life, the little pleasures it brought were no longer taken for granted.


## Fun & Games
### Crossword Puzzles
Crossword puzzles, a beloved form of word entertainment, have a fascinating history that traces back to Liverpool during the Victorian era. Arthur Wynne, a violinist-turned-journalist, created the first crossword puzzle called Word-Cross for the New York World in December 1913. He derived inspiration from a childhood word game called Magic Square, in which words were arranged in a pattern of squares to be read both vertically and horizontally.

The Word-Cross puzzle featured a diamond-shaped grid with clues for words, and soon, Wynne introduced different grid shapes and added black squares to separate the words. Initially called Word-Cross, a typographical error led to it being renamed Cross-Word, and eventually, the hyphen was dropped, solidifying its iconic name.

Crossword puzzles quickly gained popularity, and within a decade, many newspapers started incorporating them for their readers' entertainment. A crossword puzzle compilation from the New York World was published in 1924, marking the first crossword puzzle book by Simon & Schuster.

Despite its growing popularity, not everyone embraced the crossword craze initially. The New York Times, in particular, criticized it as a "sinful waste." However, they eventually changed their stance and published their first crossword puzzle in 1930.

During World War II, crossword puzzles served as a way to inject a bit of fun and diversion into newspapers alongside the grim news stories. Interestingly, the puzzle also played a role in wartime intelligence efforts. A crossword puzzle competition in London was used to identify minds adept at solving intricate puzzles, a skill deemed useful for cracking Nazi codes at Bletchley Park.

Throughout the years, crossword puzzles became a daily fixture in newspapers, growing in popularity. Different variations of the puzzle emerged, with one form gaining popularity based on wordplay and ambiguous clues, thanks to lyricist Stephen Sondheim's contribution in 1968.

In 1978, the first American Crossword Puzzle Tournament was held, attracting participants from all over, competing to solve crossword puzzles the fastest.

Will Shortz, the fourth editor of the New York Times crossword puzzle, is a prominent figure in the crossword world. While his name appears on the puzzles, he may not be the actual creator of each one.

As technology advanced, crossword puzzles found their way into the digital world, with web-based games and smartphone apps, offering enthusiasts new ways to enjoy the timeless challenge. Despite the digital options, the feeling of solving a crossword puzzle on paper with a pen remains cherished by many. The crossword puzzle continues to captivate word enthusiasts and remains a beloved pastime for people of all ages.


### The Hula Hoop
The hula hoop has a rich and diverse history that stretches back to ancient civilizations. Egyptian children played with hoops made from dried vines as far back as 3000 BC, while Greeks and Romans used hoops made of metal, wood, and vines for exercise. Hoops were also used by the Inuit for training, and they held cultural significance in various religious ceremonies, including Native American hoop dances.

The term "hula hoop" was coined by British sailors who observed the swinging hip dances of Hawaiian natives that resembled the movement needed to keep hoops spinning around the waist. Hoop dancing became popular in the late 1800s and 1900s, and Swiss composer Émile Jaques-Dalcroze introduced a hoop-based exercise called Eurhythmics.

The big craze for hula hoops erupted in the 1950s when Richard Knerr and Arthur Melin, founders of Wham-O, developed a plastic hoop inspired by Australian children's bamboo hoops. They trademarked the name "Hula Hoop" and quickly sold millions of them in the US. While the initial trend was short-lived, it gained enough popularity to be mentioned in Billy Joel's song "We Didn't Start the Fire," which celebrated 1950s trends.

Although the hula hoop remained a popular toy, its sales never matched the explosive success of the 1950s. However, it experienced a resurgence as a fitness craze in the 2000s, with celebrities like Michelle Obama, Catherine Zeta-Jones, and Kelly Osbourne incorporating it into their workouts. Beyoncé even showcased hooping skills during a performance of her song "Work It Out." Fitness classes with weighted hoops began to appear in gyms and on beaches, making the workout accessible to a wider range of participants.

### Hypnosis
Hypnosis, often associated with the power of suggestion, has roots in ancient religious ceremonies in India, Greece, and Egypt. In modern times, the precursor to hypnosis came from Franz Mesmer, a German physician in the 1700s, who believed in controlling an invisible fluid in the body through magnetism. While his magnetic fluid idea was later debunked, many of his subjects experienced improved health after being mesmerized.

The term "hypnosis" was coined by Scottish surgeon James Braid in the mid-1800s. Despite realizing that the state of mind wasn't exactly "sleep," the term "hypnosis" gained popularity and stuck. Hypnosis involves putting individuals into a focused state where they can concentrate solely on the suggestions being made to them, similar to meditation and mindfulness techniques.

Hypnosis can be used for various purposes, such as clinical hypnotherapy for habit formation or pain management. Studies have shown that hypnosis can lead to a decrease in pain-related brain activity, making it a useful tool for pain management and even during childbirth with hypnobirthing classes.

Street hypnotists performing on stage can identify those who are easily hypnotizable, known as somnambulists, who can be hypnotized on the first try. While hypnotism shows can be entertaining and engaging, participants don't lose control of themselves and are aware of their actions.

The popular pop-culture image of hypnosis with a pocket watch is not a common practice, but objects like pocket watches can be used to help focus an individual's attention during hypnosis. Overall, hypnosis is recognized in some parts of the medical community as a valid form of therapy, while others view it as a placebo effect driven by the power of suggestion and the desire to please others.

### Ping-Pong
Ping-Pong, known as table tennis in official circles due to the trademarked term "ping-pong," has a long history that can be traced back to the late 1800s when people improvised indoor equipment for lawn tennis during inclement weather. The game had various names, such as Whiff-Whaff, gossima, Flim Flam, and Pim Pam.

Over time, the game evolved with the invention of sandwich rubber for paddles in 1950, allowing players to put spin on the ball and revolutionizing the sport. Subsequent changes to rules and regulations were made in the 2000s to cater to television audiences, including a shorter scoring system and larger balls for better visibility.

Table tennis is widely popular, with an estimated forty million competitive players worldwide, and even more playing recreationally. The game is particularly popular in China, and the sport became significant in the context of "ping-pong diplomacy" during the Cold War. A chance encounter between a US ping-pong player and a Chinese player led to improved relations between the two countries, with the US team being invited to play in China, and the twenty-year trade embargo with China was lifted by the United States.

In the movie "Forrest Gump," ping-pong played a notable role in depicting Forrest Gump's skills and the use of computer-generated imagery to create captivating scenes. Tom Hanks' portrayal of Forrest Gump's ping-pong playing was enhanced with computer graphics, showcasing the movie's innovative use of visual effects, for which it won the Oscar for Best Visual Effects in 1995.

### Roller Skates
Roller skates, a popular recreational activity, have a long and fascinating history. While the origins of roller skates can be traced back to John Joseph Merlin in the 1760s, his early design lacked a braking mechanism and proper steering, leading to comical mishaps and little popularity. It wasn't until Leonard Plimpton's invention of the quad skate in 1863, with two wheels in front and two in the back, that roller skating gained traction.

During the 1970s, roller skating experienced a resurgence in popularity, thanks in part to the disco movement and its promotion as a fun and healthy exercise. Celebrities and pop culture further fueled the trend, with roller skating featuring prominently in songs, television specials, and movies, such as Roller Disco and Xanadu.

However, roller skating faced challenges during the 1980s with the decline of disco and economic turmoil, resulting in the closure of many skating rinks. It wasn't until the 1990s that rollerblading, popularized by the Olson brothers' Rollerblade brand, brought a new wave of interest in roller sports.

Today, roller skating still holds a nostalgic appeal, leading to the opening of new roller-skating rinks despite the challenges of finding suitable real estate. Roller skating races and roller derby, a contact sport played on roller skates, have also been part of roller skating culture for many years, adding excitement and entertainment to the sport.

### The Slinky
The Slinky, a beloved and iconic toy, was born from an accidental discovery by Richard James in 1943. While working on developing a spring to secure objects on ships, he inadvertently knocked a spring to the floor, and instead of falling on its side, it exhibited a mesmerizing "walking" motion. Intrigued by this unusual behavior, Richard spent two years perfecting the concept of a springy toy, eventually creating what we now know as the Slinky.

With the support of his wife, Betty, who played an essential role in naming and marketing the Slinky, the couple manufactured the toys and did an in-store demonstration at Gimbel's Department Store in Philadelphia. This demonstration turned the tide for the Slinky, as the 400 units they brought sold out in just 90 minutes.

Betty's involvement did not end there. After Richard left the company and moved to Bolivia, Betty took over and successfully turned the business around by relocating it to her hometown and launching catchy TV advertisements. Additionally, the creation of Slinky Dog, a pull-toy version of the Slinky, further contributed to the toy's popularity.

The Slinky's fame received another boost when Slinky Dog became a character in the movie Toy Story in 1995, voiced by Jim Varney. The toy was officially named the state toy of Pennsylvania in 2001. By the time of Betty's passing in 2008, more than 300 million Slinkys had been sold, making it one of the most beloved and enduring toys in history.

### The Treadmill
The treadmill, a seemingly simple yet highly effective exercise equipment, has a surprisingly ancient history. Its origins can be traced back to Rome in the late first century, where it was used as a human-powered crane to lift heavy objects. Romans would walk within the diameter of a large wheel, effectively creating a human hamster wheel that allowed them to lift more weight with fewer crew members.

Throughout the centuries, treadmills continued to be utilized for various tasks, and the term "horsepower" even originated from the measurement of a horse's strength needed to operate a treadmill or similar stationary machine for powering farms in the 1800s. In 1818, the treadmill found a grim application in the form of the prison treadmill, where convicts were made to step on spokes of a large paddle wheel for grinding corn and pumping water. Eventually, the cruelty of this practice was recognized, leading to its abolition.

However, the treadmill made a triumphant return as exercise equipment in the mid-20th century. Dr. Robert Bruce and Wayne Quinton employed a treadmill as a tool for monitoring heart conditions and diseases, developing the Bruce Protocol diagnostic test, which is still used in evaluating cardiac function today. The popularity of aerobics, developed by Dr. Kenneth H. Cooper in the 1960s to prevent coronary artery disease, also played a significant role in popularizing the treadmill for fitness.

Despite the introduction of new exercise equipment each year, treadmills remain the top-selling cardiovascular exercise machine. Their popularity is attributed to their convenience, climate control indoors, and the ability to multitask while walking on the treadmill. Whether for a quick daily walk or an intense cardio workout, the treadmill continues to be a staple in fitness routines, offering a convenient and reliable way to stay active and healthy.

### Water Guns
Water guns, a classic summer pastime, have a surprisingly long history, dating back to before they were officially patented in 1896. The concept of having playful water battles had been around for decades before that, with early water guns consisting of a pouch filled with water, attached to a cast-iron gun casing with a tube. By squeezing the pouch, water was pressurized and shot through the tube, providing a welcome relief on hot days and, sometimes, leading to mischief.

In 1858, an incident at Amherst College showcased the passion for squirt guns among students. The sophomore class held an elaborate funeral service for a stolen squirt gun, taken from the junior class. This escalated into a battle, known as the Squirt-Gun Riot of 1858, between the two classes, causing significant damage to the Ultima Thule building on campus.

Over the years, several modifications were made to the design of squirt guns, including the addition of triggers, the use of plastic instead of cast iron, and the integration of water storage in the handle. In 1977, a motorized pressure tank was introduced, but its expensive batteries limited its popularity.

The real breakthrough in water gun technology came in 1989 when Lonnie Johnson, a mechanical and nuclear engineer, developed the first Super Soaker. Utilizing a hand-pumping motion to pressurize the water stream without batteries, the Super Soaker could shoot water farther and faster than previous squirt guns. Larami, the third company Johnson approached, successfully manufactured and popularized the Super Soaker, earning its spot at the top of the toy charts in the early 1990s.

The Super Soaker's success was further solidified when it merged with Nerf in 2010, leading to continued growth for the company with new products being added to its line every summer. With its large water-bottle attachment, eliminating the need for constant refills, the Super Soaker remains a beloved and enduring favorite among kids and adults alike during the warm summer months.


## In the Home
### Band-Aids
Band-Aids, now a household name for adhesive bandages, have a history dating back to ancient times. Egyptians used honey and gauze to treat wounds and cuts as far back as 1500 BC. However, it was in the 1920s that the Band-Aid, as we know it today, was born thanks to Josephine and Earle Dickson. Josephine often suffered from minor cuts and burns around the house, and her husband, who worked for Johnson & Johnson, came up with a solution. They combined surgical tape, gauze, and stiff fabric known as crinoline to create the prototype for the Band-Aid.

Initially, Band-Aids were slow to catch on until Johnson & Johnson supplied them free to the Boy Scouts of America for their first-aid kits. The Boy Scouts embraced them and used Band-Aids as a way to earn their merit badges, leading to their widespread popularity.

In the 1950s, other companies attempted to enter the adhesive bandage market, prompting Johnson & Johnson to emphasize their product's stickiness. They demonstrated this by showing Band-Aids sticking to an egg even in boiling water. However, they were initially marketed as "flesh-colored," despite coming only in one pinkish beige shade. Later, Michael Panayiotis tried to create adhesive bandages in various flesh tones, such as Ebon-Aides, catering to black and Hispanic populations. However, these attempts faced challenges in distribution and marketing and were not as successful as hoped.

The brand name "Band-Aid" also made clever appearances in pop culture. In 1984, the famous collaboration of musicians, "Band-Aid," released the song "Do They Know It’s Christmas?" to raise funds for famine relief in Ethiopia. Additionally, in the movie Almost Famous (2000), Kate Hudson's character referred to herself and her friends as "Band-Aids," a term used instead of "groupies" for the band Stillwater.

Today, Johnson & Johnson continues to innovate, offering clear bandages to blend with various skin tones. Band-Aids remain an essential part of every household's first-aid kit, providing a quick and convenient way to cover minor wounds and promote healing.

### Diapers
Diapers, a staple in modern parenting, have evolved significantly since their ancient origins. Imagine commercials promoting absorbency using milkweed leaves or animal skin filled with grass—these were some of the early makeshift diaper materials. Over time, cloth diapers became the norm, with linen or flannel folded and pinned, often left unchanged for days.

In the 1930s, a disposable diaper insert made from paper and softwood pulp was introduced in Sweden, primarily catering to families on the go. However, it wasn't until after World War II that the demand for more convenient diapers increased, as women who had been supporting their families while men were at war had less time for washing cloth diapers.

Marion Donovan, a resourceful housewife and mother of two, created a waterproof diaper cover, which she named the Boater, to tackle the diapering challenges she faced. Her invention featured plastic snaps to replace the troublesome diaper pins. Although manufacturers initially rejected her idea, Donovan started producing and selling the Boaters herself, eventually finding success.

In 1948, Johnson & Johnson introduced Chux, an alternative to cloth diapers imported from Sweden. While popular for travel, it laid the groundwork for disposable diaper adoption. Victor Mills, a chemical engineer at Procter & Gamble, later developed Pampers, the first successful disposable diaper. After overcoming initial challenges, Pampers became a leading brand, and other companies followed suit.

In the early 1980s, a diaper war erupted, with Kimberly-Clark's Huggies competing against Procter & Gamble's Pampers. The dispute was resolved in 1992, with Kimberly-Clark emerging as the top brand in America.

Pediatrician Dr. T. Berry Brazelton's advice on letting children decide when to quit diapers coincided with Pampers introducing larger diapers for older children. While some saw this as a positive approach, others criticized the potential conflict of interest between Brazelton and the diaper company.

Today, the eco-friendly reusable diaper trend has gained momentum, providing parents with another option to consider in the ever-evolving world of diapering.

### The Dishwasher
The history of dishwashing dates back to ancient times when pottery and cookware were essential artifacts for human life. Settling near water sources in the Fertile Crescent allowed early civilizations to access water for drinking, irrigation, and cleaning dishes. Washing dishes was initially a manual task, requiring individuals to carry their cookware to water sources or bring water to their homes for hand-washing.

The concept of a dishwasher began to take shape in the 19th century, with various inventors attempting to create an automated machine for dishwashing. In 1850, Joel Houghton patented a wooden machine with a hand-turned wheel, but it was not very efficient and required significant manual labor. Wealthy individuals, like Josephine Garis Cochrane, had the luxury of hiring servants to handle dishwashing, but she grew frustrated with her china getting chipped and broken during the washing process.

Cochrane, whose family had a history of innovation, decided to develop a machine that could wash dishes more efficiently. She came up with the idea of a rack that held dishes in place while water pressure washed and rinsed them. Cochrane meticulously measured plates and cups and designed wire compartments to hold them, which would then be placed in a copper boiler. The dishes would turn on a wheel while hot soapy water cleaned them.

In 1886, Cochrane filed a patent for her dishwasher design after facing skepticism from some engineers who doubted her capabilities. Her dishwasher initially faced challenges in gaining popularity among housewives, but it found success in hotels and restaurants. Cochrane showcased her invention at the 1893 World's Columbian Exposition. Her company, the Garis-Cochran Manufacturing Company, eventually became KitchenAid and is now part of Whirlpool.

While dishwashers took some time to become readily available for households, they eventually became a common household appliance, often sporting vibrant colors popular in the '70s. Despite their popularity, some smaller kitchens still require hand-washing due to the space limitations posed by traditional dishwasher units.

### The Lead Pipe
The use of pipes and plumbing dates back to ancient times, with copper pipes found in palace ruins in India from around 3000 BC. The Romans used lead, bronze, and marble in their aqueducts for water supply from 500 BC to the mid-fifth century AD. Lead, known as "plumbum" in Latin, was a popular metal in Western civilization for various applications, including waterworks and cookware.

Despite its widespread use, there were concerns about the health effects of lead. Vitruvius, an architect under Caesar and Augustus, remarked on the potential harm of water conveyed through lead pipes. He observed the poor health of those working with lead and warned about the dangers of lead exposure.

Lead poisoning, caused by ingesting or inhaling lead, was a real issue, and it's believed that lead poisoning contributed to health problems in ancient times. However, the fall of Rome cannot be solely attributed to lead pipes since the mineral deposits from hard water created a buffer between the lead and the water flowing through the pipes.

In the context of the game Clue and its movie version, where a lead pipe is one of the weapons, a playful rabbit hole is explored. Considering the character Mr. Boddy's age and the historical prevalence of lead, it's suggested that he may have been exposed to lead in various ways throughout his life. From leaded gasoline and lead paint to lead-glazed dishes and toys, the character's health might have been affected in some manner by a lead pipe, even if it didn't directly cause his fictional demise in the game.

### The Paper Bag
Paper bags may seem unremarkable, but their history is quite intriguing. Before the 1800s, people used fabric sacks, paper tied with twine, or straw baskets for carrying items. However, in 1852, Francis Wolle invented a machine that quickly folded paper into envelope-like bags, revolutionizing paper bag manufacturing. This led to the formation of the Union Paper Bag Company in 1869.

Another key figure in the paper bag's evolution was Margaret "Mattie" Knight. Known for her inventive nature since childhood, she worked at the Columbia Paper Bag Company when she heard about attempts to create a machine for making flat-bottomed bags. Undeterred, she took on the challenge, working long nights to conceptualize a machine that would fold the bottom together using a "plate knife holder." Despite facing patent disputes and prejudice against female inventors, Knight won the court battle and was granted a patent for her design in 1871.

Following Knight's innovation, Charles Stilwell further improved the design by adding pleated sides, leading to the creation of the "SOS" (Self-Opening Sack). This design laid the foundation for modern-day paper bags. Over time, plastic bags gained popularity due to their cost-effectiveness, leading to a decline in paper bag usage.

In recent times, concerns about environmental impact have prompted some stores to charge for disposable bags, encouraging customers to bring their own reusable bags. There is ongoing debate about which type of bag is better for the environment. Plastic bags require fewer resources to produce but have lower recycling rates, while paper bags disintegrate faster and are more likely to be recycled or reused by consumers.

Despite the rise of plastic bags, the history of paper bags is filled with ingenuity and innovation, making them an essential part of our everyday lives, even if their story often goes unnoticed.

### Solar Panels
The history of solar panels dates back to ancient civilizations that revered and worshiped the sun. However, it was not until 1839 when French scientist Edmond Becquerel discovered that sunlight could create electrical voltage. This discovery sparked scientific interest in harnessing solar power for everyday use.

Early attempts at commercializing solar power faced challenges due to the high cost of materials. Despite this, inventors like August Mouchet and Willoughby Smith continued to experiment with solar energy during the 1800s. Albert Einstein's work on photons and energy packets furthered the understanding of light and its potential for generating electricity.

One remarkable pioneer in solar energy was Maria Telkes, who developed a solar-powered distiller during World War II that could turn seawater into drinking water. She went on to build the first solar-heated house in Dover, Massachusetts, in collaboration with architect Eleanor Raymond. Telkes also contributed to the development of solar-powered stoves and heaters, as well as the construction of the first solar-electric residence in 1980.

As technology in the field of solar energy advanced, solar panels became more efficient and accessible. Today, solar panels can be found on top of buildings and in large power-plant arrays worldwide, with many individuals and organizations embracing solar power as a way to reduce reliance on fossil fuels and lower electricity bills.

And if the topic of solar panels doesn't intrigue you enough, there's always the cult classic movie Birdemic, which humorously portrays the adoption of solar panels by a few inspired viewers.

### Tissues
Tissues, as we know them today, have an interesting history that traces back to ancient civilizations using handkerchiefs made of linen. Handkerchiefs were primarily used to shield the face from the sun and wipe off sweat. The term "handkerchief" itself evolved from Old French, originally meaning "head cover."

Throughout history, handkerchiefs gained popularity, especially when Catherine de Medici introduced lace-bordered and scented versions in France. Shakespeare even featured a handkerchief as a pivotal object in his play "Othello."

Marie Antoinette's association with handkerchiefs further contributed to their popularity. While the story of her tearing pieces of lace to wipe her tears may be folklore, she did influence the standardization of handkerchief sizes.

During the nineteenth century, men started using handkerchiefs as pocket squares to add flair to their suits. Handkerchiefs were also given as romantic tokens during World War II, and they had practical uses, such as printing maps on silk handkerchiefs for pilots.

The modern tissue as we know it originated in 1924 when Kimberly-Clark Corporation introduced Kleenex, initially intended for makeup removal. However, customers found them more suitable for blowing their noses. During World War II, Kleenex's manufacturing was redirected for bandages and wound dressings due to rationing. After the war, Kleenex became a household name, and its brand name eventually became synonymous with tissues in general.

Overall, the evolution of handkerchiefs into disposable facial tissues revolutionized hygiene practices and introduced a more convenient and hygienic way of dealing with colds and other nose-related issues.

### The Toothbrush
The act of brushing our teeth, which seems perfectly normal to us, has been the subject of curiosity and even satire in the past. In 1956, Horace Miner wrote a satirical piece titled "Body Ritual Among the Nacirema," where he described Americans' daily rituals, including the seemingly strange practice of brushing their teeth. The term "Nacirema" is just "American" spelled backward, highlighting the cultural biases and perceptions present in anthropological studies.

Interestingly, while we are diligent about oral hygiene, humans are the only species known to actively brush their teeth. Some myths about animals, like crocodiles getting dental hygiene from birds, have been debunked. In reality, the need for toothbrushes arises from our diet, which often includes sugar and processed food that can damage our teeth.

Early toothbrushes were quite different from the ones we use today. In ancient Egypt, people used their fingers to brush their teeth with a mixture of ash, myrrh, eggshells, and pumice. Chew sticks with frayed ends were also used, as well as brushes made of horsehair or boar bristles in various regions. The term "toothbrush" was first recorded in 1690, but the modern toothbrush with an animal bone handle and coarse animal hair bristles was attributed to William Addis, who created it during his time in prison in 1780.

During the Industrial Revolution, toothbrushes became a status symbol, reserved for the wealthy. However, dental hygiene gained more attention and importance when schools made education mandatory for children in the early 1900s. Dentists were brought into schools to teach proper dental care, and toothbrushes were given away or sold at low prices to encourage the habit.

In 1937, nylon was invented, and this new material replaced animal hair for toothbrush bristles. The same year saw the invention of the electric toothbrush, which further revolutionized dental care.

Overall, the history of the toothbrush highlights the evolution of oral hygiene practices and the increasing awareness of the importance of dental care for overall health. Today, we continue to brush our teeth diligently, thanks to centuries of innovation and awareness-building efforts.


## Music
### Lullabies
Lullabies have been an essential part of soothing babies to sleep for centuries, with their history dating back to ancient Babylon around 2000 BC. One of the earliest known lullabies was found on a clay tablet in Babylon, but surprisingly, its lyrics were far from the soothing and gentle lullabies we know today. Instead, it warned the child to sleep or face the wrath of a demon.

Lullabies, throughout history, have often contained darker or morbid elements. The popular lullaby "Rock-a-bye Baby" depicts a tragic scene of a baby falling from a tree branch. Such lullabies, passed down through generations, have evolved over time and may not always be family-friendly. However, babies don't comprehend the lyrics' meaning; it's the calming melody that helps soothe them.

In the womb, babies experience limited external stimuli, but they can hear muffled sounds, particularly their mother's voice. Lullabies sung by the mother can create a comforting bridge between the prenatal and postnatal worlds. Even the voices of others the baby hears in utero can have a similar effect.

The effectiveness of lullabies lies in their soothing tones and gentle rhythms. Familiar voices singing lullabies have been found to be most effective at calming children, and singing lyrics or reciting nursery rhymes can support early language development. Music in general has proven beneficial for babies and young children in aiding learning.

Various lullabies use the 3/4 time signature, also known as the waltz time, which mimics rocking motions and is common in traditional lullabies from around the world. Brahms' "Lullaby," also known as the "Cradle Song," is one of the most recognizable and beloved lullabies. Its origins are connected to a woman named Bertha Faber, and Brahms may have written it as a love song for her.

As for "Twinkle, Twinkle, Little Star," often attributed to Mozart, the melody actually came from an old French song. Mozart composed twelve variations based on the melody, and the lyrics were later added by English poet Jane Taylor.

The origins of other well-known lullabies like "Rock-a-bye Baby" and "Hush Little Baby" are more challenging to trace, but their melodies have become deeply ingrained in popular culture.

Lullabies continue to be a cherished and effective way to comfort babies and support their early development. Whether singing traditional lullabies or more modern renditions, the power of music to calm and connect with infants remains timeless.

### Musicals
In this special episode of The Story Behind, the history of musicals is cleverly sung to the tune of "The Major-General's Song" from The Pirates of Penzance. The journey of musicals begins in ancient Greece, where theaters with impressive acoustics were prevalent. The Middle Ages brought a resurgence of musicals through church performances and traveling minstrels.

The 17th and 18th centuries saw musicals taking a satirical and comical approach, contrasting the seriousness of operas. Despite facing criticism from imperial figures, musicals remained popular and continued to spread across different regions, with names like Strauss and Offenbach contributing to their geographical reach.

In the USA, Vaudeville shows gained popularity and became a significant part of the musical landscape. The rise of Broadway further solidified musicals as a major force in the theatrical world, with stage revues like Ziegfeld's follies attracting international crowds.

The 1919 actors' strike led to unions securing contracts with a picket line, and the 1920s brought forth talented composers like Cole Porter, Rodgers, and Hammerstein. The Great Depression did not deter the musicals' progress, but many actors sought opportunities in Hollywood as movies embraced sound.

Musicals flourished as people sought escapism during World War II, and records of musical soundtracks became popular. Rock 'n' roll emerged and momentarily challenged musical theater, but the genius of Stephen Sondheim revitalized the genre with his concept shows.

Andrew Lloyd Webber's epic scores and the success of movies-turned-musicals further solidified musicals' place in the hearts of audiences. Today, the tradition continues, and Lin-Manuel Miranda's R&B-inspired musicals, like Hamilton, have taken center stage.

The episode concludes with a nod to Episode 100, where the history of musicals was masterfully presented. Through this song-filled journey, listeners learn about the rich and dynamic history of the modern major musical.

### The Theremin
The theremin, though not widely known by name, has a sound that many are familiar with due to its frequent use in sci-fi and horror movie soundtracks. Invented by Lev Sergeyevich Termen, also known as Leon Theremin, around 1920, it remains one of the weirdest-sounding and most intriguing musical instruments to this day.

Originally a Russian physicist studying electromagnetic fields during the First World War, Termen stumbled upon the idea of creating music by moving his hands between two electromagnetic fields using a dielectric device he had developed. This led to the creation of the theremin, the first instrument that could be played without physical contact.

Impressed by the invention, Vladimir Lenin sent Theremin and his instrument on a tour across Russia to showcase its capabilities. In 1928, Theremin was sent to the United States by RCA to promote and mass-produce the theremin. However, due to the 1929 stock market crash, the initial attempt to market the instrument was not successful.

Mysteriously, in 1938, Theremin vanished from the United States, leaving his wife and business behind. He resurfaced years later in Russia after the fall of the Iron Curtain, where he was arrested and imprisoned for reasons that remain unclear.

The theremin experienced a resurgence in popularity in the 1950s and '60s when Hollywood began using it in science fiction movie soundtracks. Robert Moog, known for the Moog synthesizer, later sold build-it-yourself theremin kits, contributing to the instrument's renewed popularity.

Contrary to popular belief, the sliding instrument heard in the Beach Boys' "Good Vibrations" is not a theremin but an electro-theremin, a simpler alternative. However, Led Zeppelin's Jimmy Page did incorporate a theremin-like instrument in the solo of "Whole Lotta Love" and throughout "No Quarter."

Despite its unusual nature, the theremin remains an intriguing and captivating instrument. It has even made appearances in popular culture, including an episode of The Big Bang Theory where Sheldon Cooper plays the theremin, mistaking its sound for the original Star Trek theme, which was, in reality, sung by Loulie Jean Norman, a renowned soprano.


## Out & About
### The Fire Hydrant
The fire hydrant, an essential tool for firefighting, has a long history dating back to the need for ways to combat fires throughout the ages. Early methods involved bucket brigades and hollowed-out logs as water pipes. The Great Fire of London in 1666 led to the implementation of pre-drilled holes and plugs in the water system, with cast-iron pipes replacing wooden ones in larger cities.

Frederick Graff Sr., often credited with inventing the above-ground fire hydrant we know today, played a crucial role in creating Philadelphia's first water system, including pillar-shaped hydrants for easy access to water by firefighters. Although his initial system proved inadequate, he continued to improve it and succeeded in creating an effective design in 1822.

The early fire hydrants were metal pipes encased in wood with a valve at the bottom and an outlet on the side. One challenge faced was preventing water inside the hydrants from freezing during colder months. To address this, adjustments were made to the valve location, lowering it below ground level so that water could empty from the hydrant after each use. This resulted in two types of hydrants: dry-barrel hydrants, which are common in areas with freezing temperatures, and wet-barrel hydrants used in areas where freezing is less likely.

Fire hydrants can be differentiated by their color, indicating the water pressure they provide. Yellow hydrants are typically connected to city water supplies, while red ones are used in more rural areas or for special operations. Purple hydrants often draw water from nearby lakes or ponds and are considered non-potable. Blue and green hydrants are common in metropolitan areas, where higher water pressure is needed.

Insufficient water flow from a hydrant can lead to a potentially hazardous situation where the water system may draw in polluted and untreated water from the ground, resulting in a Boil Water Advisory. As such, maintaining and ensuring proper water pressure in fire hydrants is crucial to effective firefighting efforts.

### Gas Masks
Gas masks have a long history, with early versions used to protect wearers from noxious fumes and smells. One of the earliest known masks was a simple sea sponge used in ancient Greece, while in 850 AD, the Banu Musa brothers from Iraq invented a mask for workers in polluted wells.

The iconic beaked mask associated with the Plague Doctor ensemble was designed by Doctor de Lorme in the seventeenth century. It included dried flowers and herbs inside the beak to help the doctor breathe more pleasant-smelling air while treating patients.

In the early 1800s, the diving mask emerged, which allowed individuals to go underwater while oxygen was pumped through a tube. The first US patent for an air-purifying respirator was given to Lewis P. Haslett in 1849 for a device that filtered dust from the air. Scottish chemist John Stenhouse later used a charcoal filter, still commonly used today for air and water filtration.

Garrett Morgan's gas mask and safety hood gained attention when he used it to rescue thirty-two men trapped by an explosion in an underground tunnel in 1914. His design became the basis for army gas masks used during World War I, offering protection against mustard gas and other harmful agents.

John Scott Haldane, a Scottish medical researcher, played a crucial role in identifying chlorine gas used during World War I and began developing a respirator to protect against it. His work marked the beginning of modern respirators.

In popular culture, gas masks are infamously associated with a certain Lord of the Sith from a galaxy far, far away. In modern times, gas masks are recommended for nuclear attack survival kits, with NBC-approved masks protecting against nuclear, biological, and chemical gases, while CBRN-approved masks also include radiation protection.

Proper fit and an airtight seal around the face are crucial when selecting a gas mask, and beards can disrupt the seal. Some masks even come with devices to allow drinking while wearing them.

### Mad Hatters
The use of mercury nitrate in the hat-making industry, known as carroting, was widespread in the 1600s after the Huguenots shared the secret with England. However, prolonged exposure to mercury caused hatters to exhibit symptoms such as anxiety, depression, and trembling, known as "hatters' shakes." This led to the phrase "mad as a hatter" in everyday speech to describe someone with similar symptoms to mercury poisoning.

One famous individual believed to have suffered from mercury poisoning was Boston Corbett, the man who killed John Wilkes Booth after the assassination of Abraham Lincoln. Corbett's erratic behavior and disappearance later in life further fueled the association with mercury poisoning.

In the 1940s, the use of mercury in hat-making was finally banned in the United States. The Mad Hatter character from Lewis Carroll's "Alice's Adventures in Wonderland" is often associated with mercury poisoning, but this theory is not entirely accurate. The original character was not described as suffering from shaking, and scholars believe the character may have been based on an eccentric porter and cabinet maker named Theophilus Carter from Oxford, England. Carter was known for wearing a large top hat and displaying an alarm-clock bed invention at the Great Exhibition in 1851.

While Carroll denied basing his characters on real people, the resemblance between Carter and the Mad Hatter's illustrations in the book adds to the speculation that Carter might have been an inspiration for the character. However, the true origins remain unclear.

### The Smiley Face
In 1963, Harvey Ross Ball, a graphic designer, created the iconic smiley face as a morale booster for the State Mutual Life Assurance Company. The design, which originally began as just a smile, but later had eyes added to prevent it from being turned into a frown, was created in just ten minutes, and Ball was paid $45 for his work. However, neither he nor the company trademarked the design, leading the Spain brothers, owners of Hallmark stores, to add the catchphrase "Have a happy day" and copyright the design.

The smiley face quickly became popular and was seen all over the world. In France, Franklin Loufrani began using the symbol in the publication France Soir and trademarked it as the "Smiley," marketing it globally on transfers for T-shirts. The origin of the smiley face has been disputed over the years, but due to its simple design, it's challenging to determine the true originator.

In 1997, the Smiley Company attempted to trademark the symbol, but Walmart, which had been using the smiley face in its branding since 1996, contested the move, resulting in a legal dispute that was eventually settled out of court after years of litigation.

Forrest Gump incorporated a nod to the smiley face's popularity in the movie, and in 1994, a Seattle man named David Stern falsely claimed to be the inventor of the smiley face during his mayoral campaign, which was debunked by the local newspaper.

Harvey Ball, feeling that the smiley face had lost its original meaning, created the World Smile Corporation and established World Smile Day to support charitable causes. He passed away in 2001, and the smiley face design is still used by Worcester Mutual Fire Insurance, now known as Worcester Mutual Fire Insurance, on its promotional materials. :)

### The Traffic Light
The history of traffic lights is an interesting journey through the early days of automobiles and the challenges they presented on the roads. As cars became more commonplace in the early 1900s, accidents started to increase due to the lack of established rules of the road. Some states implemented measures to reduce accidents, such as requiring a person with a red flag to walk in front of moving vehicles.

In 1912, the first electric traffic signal was created by Lester Wire in Salt Lake City, Utah, featuring red and green lights. The first electric traffic light based on James Hoge's design was installed in Cleveland, Ohio, in 1914, controlled from a control booth.

Dr. John A. Harriss designed a simple two-light signal that significantly reduced travel time in New York City. In 1920, his signal cut a 23-block trip from forty minutes to just nine. An architect named Joseph Freedlander designed an ornate set of signals for Fifth Avenue, featuring a brass statue of the Greek god Mercury on top.

However, the most recognizable version of the traffic light, the three-signal design, was invented by Garrett Morgan, an African American inventor born in 1877. Morgan patented various inventions, including a chemical hair straightener and a safety hood that served as a precursor to modern gas masks.

After witnessing an accident between two carriages in Cleveland, Morgan came up with the idea for a third signal as a warning for pedestrians and motorists. He received a patent in 1923 for his T-shaped three-signal traffic light and sold the patent to General Electric.

As for the colors used in traffic lights, the reason for red and green comes from the colors already being commonly used on equipment. Red indicated that the machine was stopped, while green indicated that it was running. Another theory is that red has the longest wavelength, making it easier to see from a distance, while green, having a shorter wavelength and scattering more, appears white from a distance. Yellow light, being almost as visible as red, is often used in caution signs like school zones or crosswalks.

### Windshield Wipers
Windshield wipers are a crucial feature on modern cars, ensuring visibility during inclement weather. But did you know that one of the earliest patents for this essential mechanism was granted to a woman named Mary Anderson? She had a brilliant idea while riding in a streetcar during a sleet storm in New York City. Observing the driver continually stopping the vehicle to manually remove debris, she envisioned a mechanism that could be controlled from within the car to clear the windshield. That very same day, she began sketching her design, made of wood and rubber, which drivers could activate with a lever.

In 1903, Anderson patented her idea and attempted to market it to early automobile manufacturers. However, her invention was met with skepticism and dismissals. Manufacturers claimed they couldn't see the commercial value of such a product and believed the sweeping motion of the wiper would distract the driver.

A few years later, in 1916, John Oishei of Buffalo, New York, got into an accident while driving in the rain. This incident inspired him to look for a safer solution for motorists in bad weather. He came across an existing hand-operated rubber wiper known as the Rain Rubber and founded a company to market it.

Around the same time, a vaudeville actress named Charlotte Bridgwood, known as Lotta Lawrence, patented an electric wiper system powered by the car's engine. However, neither Anderson nor Bridgwood received credit or financial compensation for their contributions.

In some versions of windshield wipers' history, it was Bridgwood's daughter, Florence Lawrence, who is credited with inventing electric windshield wipers, with her mother assisting her in obtaining the patent.

Windshield wipers finally became a standard feature in automobiles when Ford added them to the Model T in 1913, and Cadillac followed suit by making them standard on their vehicles in 1922. Since then, windshield wipers have become an indispensable part of all cars on the road, providing drivers with clear visibility in all weather conditions.


## Technology
### Caller ID
Once upon a time, in a world before everyone carried phones in their pockets, households shared just one phone, attached to the wall. When that phone rang, it was a mystery as to who could be on the other end. It could be a friend or family member, but it could also be a dreaded telemarketer. This was the era before Caller ID, and prank calling was a mischievous pastime for kids.

The story of Caller ID begins with Theodore George Paraskevakos, who developed a transmitter and receiver capable of recognizing phone numbers of incoming calls in 1968. Phone companies saw the potential of this technology and wanted to capitalize on it by charging customers a per-use fee and providing voice announcements for each new call. However, John Harris had the idea to incorporate a screen into telephone units to display the caller's telephone number. The prototype, developed with Kazuo Hashimoto, allowed users to program names associated with familiar numbers by hand.

By 1984, Caller ID started showing up in households with the help of phone book directories. The technology expanded further with Dr. Shirley Ann Jackson's contributions, which included Call Waiting and portable fax technology. Caller ID became even more useful with the introduction of Call Waiting in 1995, allowing users to decide whether an incoming call was more important than the one they were already on.

As cell phones gained popularity and house phones fell out of favor, Caller ID faced new challenges. Advanced systems can still display names associated with cell phone numbers, but cell-to-cell calls often don't use this technology as often. Today, we program names and numbers into our cell phones with ease, but it's amusing to think about the times when programming names involved using the letters associated with the number keys.

While we may have advanced in our communication technology, some apps can now detect potential spam calls, taking us back to a time before Caller ID. Nevertheless, Caller ID has left a lasting impact, and we can still look back at its introduction with nostalgia and appreciate the convenience it brought to our lives.

### Kevlar
The quest for a true bulletproof material has been ongoing for centuries, with early attempts using heavy metal armor that proved ineffective against many firearms. However, in the 1800s, Japan and Korea discovered that layering tightly woven silk could withstand bullets of that era. Inspired by this, Casimir Zeglen, a Polish monk living in Chicago, sought to improve upon the idea and created a lightweight vest using a steel plate between layers of silk. His invention was put to the test in front of a live audience, and it was able to stop bullets at close range.

Zeglen's vest was tested by the US military but was deemed too hot and expensive for widespread use. Despite this setback, Zeglen offered the vest to President William McKinley, who unfortunately was shot before their meeting. Zeglen's vest would have been able to protect the president from the fatal shot, but the incident damaged the reputation of the vest.

The true breakthrough in bulletproof material came when Stephanie Kwolek joined DuPont in 1946 and discovered Kevlar, a synthetic plastic that was significantly stronger than steel. Patented in 1966, Kevlar found its first applications in protective vests for police officers. Today, it has hundreds of applications, including underwater cable coverings, building materials, gloves, firefighter boots, hockey sticks, and car tires.

Researchers continue to search for even better materials, with "Spider Silk," made from genetically-engineered silkworms, showing promise as a future option. Despite the challenges in creating a truly bulletproof material, innovations like Kevlar have saved numerous lives and continue to be essential for protection in various industries.

### Podcasts
Podcasts, a portmanteau of "iPod" and "broadcast," have become a popular medium for audio content consumption. The term "podcasting" was coined by Ben Hammersley in a 2004 Guardian article, and while some have suggested alternatives like "netcast," the term "podcast" has stuck and is widely used.

Podcasting became possible thanks to the inventions of the RSS feed and the MP3 file format. An RSS feed allows listeners to subscribe to a podcast and receive new episodes automatically when they are uploaded. MP3 is a coding format that compresses audio files without significant loss of quality, making it ideal for podcasting.

Adam Curry, a former MTV VJ, is credited with popularizing podcasting for audio files, while software engineer Dave Winer is known for creating the RSS feed technology. The first voice to be released as a downloadable MP3 on an RSS feed was Christopher Lydon in 2003.

Podcasts cover a wide range of niche interests, and podcast listening has been steadily growing year after year. With the introduction of Apple's Podcasts App for iPhone in 2012, even more people discovered and embraced this form of audio content.

In 2014, Chicago Public Media's This American Life launched a spin-off show called Serial, which garnered significant attention and further boosted the popularity of podcasts. Podcasters and listeners often share their favorite shows through word of mouth, contributing to the industry's continued growth.

Every September 30th, podcasters and enthusiasts come together to celebrate International Podcast Day, appreciating the wealth of audio content available in the podcasting world.

### Voice Recognition
Voice recognition technology has come a long way since its inception in 1952 when Bell Laboratories introduced "Audrey," a machine capable of recognizing spoken numbers zero through nine. Although Audrey was huge and required close familiarity with the speaker for accuracy, it marked the beginning of voice recognition technology.

In the 1970s, the Defense Advanced Research Projects Agency (DARPA) developed "Harpy," which could understand over one thousand words, advancing speech recognition technology further. However, it was still a far cry from the sophisticated voice recognition depicted in science fiction shows like "Star Trek" and "Star Wars."

In the 1980s, Julie, the voice-responsive doll, captured the imagination of kids, but the technology wasn't yet fully developed, leading to some disappointments with its responsiveness.

Voice recognition software relies on recognizing phonemes, which are the smallest elements of spoken words, to determine what word the speaker is most likely saying. It doesn't always catch every phoneme, leading to occasional errors or inaccuracies.

Dragon Dictate, introduced in 1990, became the first speech recognition program for consumers. While it was an improvement, it had limitations, and better versions like Dragon NaturallySpeaking were introduced over time.

BellSouth's introduction of the first voice portal called VAL in 1996 brought the convenience of voice-activated information access over the phone, with applications ranging from movie times to customer service.

The choice of female voices for voice-activated assistants like Siri and others is intentional, as movies often portrayed male computer voices as menacing and evil.

While modern voice-activated assistants use synthesized voices, the original voice of Siri was reportedly provided by Susan Bennett, a voice actor from Atlanta, who recorded phrases for an unknown project back in 2005.

Voice recognition technology has made tremendous strides over the years, and with ongoing advancements, it continues to play an essential role in our everyday lives.

## Weapons
### Gunpowder
The origin of gunpowder can be traced back to ancient Chinese scientists' search for the elixir of life. They experimented with saltpeter, a chemical compound formed from decomposing animal manure, and combined it with sulfur and charcoal. Little did they know that this concoction would turn out to be highly explosive.

Alchemists, in their pursuit of the elixir of life, discovered that the combination burned quickly and intensely, leading to its use in fireworks during celebrations. Recognizing its potential as a weapon, the Chinese started using gunpowder-based weaponry to defend against invading forces, such as the Mongols.

As the knowledge of gunpowder spread, it reached Europe and the Islamic world, leading to the development of cannons, grenades, and handguns. With each advancement in gunpowder weaponry, defenses had to be improved, leading to an arms race that continues to this day.

One historical event associated with gunpowder is the Gunpowder Plot of 1605 in England. Robert Catesby and Guy Fawkes planned to blow up the Parliament building, but Fawkes was captured before carrying out the act. He was subsequently sentenced to be hanged, drawn, and quartered, but he died by breaking his neck. November 5, the day Fawkes was captured, is now celebrated in the UK as Bonfire Night or Guy Fawkes Night, with fireworks displays and burning effigies.

Gunpowder's discovery had far-reaching effects on the course of history, shaping warfare and defenses throughout the centuries. From its early use in celebrations to its deadly applications in battle, gunpowder has left an indelible mark on human history.

### The Revolver
The revolver, also known as the multi-shot revolving firearm, was patented by Samuel Colt in 1836. The idea for the revolver came to him when he was inspired by the rotating wheel of a ship and applied the concept of a clutch to create a rotating cylinder of bullet chambers for a single-shot pistol. However, he initially lacked the funds to develop his invention, so he took to the streets as a street performer under the name Dr. Coult, entertaining crowds with laughing gas.

Colt's street performances were successful, and he used the money he saved to implement assembly-line techniques from the Industrial Revolution in manufacturing his revolvers. By the time the Civil War started, Colt's revolvers had become increasingly popular, partly due to his promotion tactics, which involved having famous artists and writers incorporate them into their work.

One of the most well-known revolvers is the Colt .45, also known as the Colt Single Action Army handgun. Despite its fame, Samuel Colt never had the chance to hold one in his hands, as it was released to the public ten years after his death in 1862. The Colt .45 gained legendary status and played a significant role in the Wild West, from being used in duels to helping settle the West.

The Colt .45 was favored by various historical figures, including Theodore Roosevelt's Rough Riders, outlaws like Billy the Kid and Jesse James, and even entertainer Annie Oakley. Its popularity was further boosted by early cowboy movies and television Westerns. Although its manufacturing slowed during World War II, the resurgence of Westerns in the 1950s brought the Colt .45 back into the mainstream. Notably, actor John Wayne sported ivory-gripped Colt .45s as his signature pistols.

On a side note, it's interesting to mention that the malt liquor called Colt .45 was not named after the Peacemaker revolver. Instead, it was named in honor of 1963 Baltimore Colts running back Jerry Hill, whose jersey number was 45.

