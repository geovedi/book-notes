# Research Methods: Designing and Conducting Research with a Real-World Focus

**Authors**: Carrie A. Picardi, Kevin D. Masick | **Year**: 2014

## Summary

This comprehensive research methods textbook bridges the gap between academic research and practical application, providing students and practitioners with the tools to conduct high-quality research in real-world settings. The book emphasizes the critical relationship between reliability and validity while addressing the ethical challenges researchers face in field settings. Rather than presenting research as a purely academic exercise, Picardi and Masick demonstrate how sound methodology can solve everyday organizational problems and advance scientific knowledge simultaneously.

Ideal for students, practitioners, and anyone who needs to conduct or evaluate research, this guide transforms complex methodological concepts into accessible frameworks that can be applied immediately in professional contexts. The book's unique strength lies in its focus on the "science-practice gap" and how thoughtful research design can deliver both academically rigorous and practically valuable results.

## Core Insights

### Foundation of Research Design

Research methodology provides a systematic framework for understanding human behavior and solving real-world problems. The four main research categories—experimental, quasi-experimental, nonexperimental, and survey designs—each serve distinct purposes and come with specific advantages and limitations. Understanding when to use each approach depends on your research questions, available resources, and the practical constraints of your setting. The key insight is that research design is both an art and a science: creativity in approach combined with methodological rigor.

> "The only limitation between what you want to do and what you actually get to do is dependent upon your own creativity and ability to reduce validity threats, aside from concerns of ethics and constraints of time and resources."

**Quick Take**: Start with clear research questions, then match the design type to your practical constraints rather than forcing your situation into a predetermined methodology.

### Variables, Measurement, and Hypotheses

Every research study involves manipulating independent variables and measuring dependent variables, but the quality of your results depends on proper operationalization and measurement. Variables can be measured on four scales: nominal (categories), ordinal (ranks), interval (equal intervals), and ratio (true zero). Each scale dictates what statistical analyses are appropriate and what conclusions you can draw. Your hypotheses should be theory-driven, specific, and testable—moving from broad questions to precise predictions that can be empirically evaluated.

> "The world of research is a complicated one. Whether you are learning to become a researcher or being a consumer of information, you will have to critically conduct or evaluate research."

**Quick Take**: Spend as much time defining and measuring your variables as you do designing your research—poor measurement guarantees meaningless results regardless of how well-designed your study is.

### Research Ethics and Legal Compliance

Ethical research is non-negotiable. Modern ethical standards emerged from dark chapters in research history, including the Nuremberg Trials, Milgram's obedience studies, and the Tuskegee syphilis experiments. Today's researchers must follow three core principles: respect for persons (voluntary participation), beneficence (maximizing benefits while minimizing harm), and justice (fair distribution of risks and benefits). This means obtaining informed consent, ensuring confidentiality, protecting vulnerable populations, and being transparent about limitations and conflicts of interest.

> "Ethical behaviors and actions should result in more good than harm and should have positive consequences for as many individuals as possible, also referred to as the greater good."

**Quick Take**: Build ethics into your research design from the start—ethical considerations aren't obstacles to overcome but fundamental requirements that shape good science.

### Reliability: The Foundation of Valid Measurement

Reliability refers to the consistency of your measurements, and it's a prerequisite for validity. You can't have valid results if you can't measure your variables consistently. Five types of reliability are essential: test-retest (consistency over time), interrater/intrarater (consistency across raters), parallel forms (equivalent test versions), split-half (internal consistency), and internal consistency (Cronbach's alpha). Remember the two fundamental principles: reliability is necessary but not sufficient for validity, and reliability sets the upper limit for validity—your validity coefficient can never exceed your reliability coefficient.

> "A measure can be reliable and not valid, but it cannot be valid and not reliable. Additionally, reliability is a necessary, but not sufficient, condition for validity."

**Quick Take**: Aim for reliability coefficients of 0.70 or higher, but don't assume high reliability automatically means you're measuring the right thing—always consider validity separately.

### Validity: Ensuring Accurate Conclusions

Validity refers to the accuracy of your research conclusions and comes in multiple forms. Statistical conclusion validity ensures your statistical analyses are appropriate, internal validity protects against alternative explanations for your results, construct validity confirms you're measuring what you think you're measuring, and external validity allows you to generalize your findings. Each type of validity faces specific threats that researchers must anticipate and address through careful design choices, proper measurement, and appropriate statistical analyses.

> "The goal of being a consumer of information is to know and understand the various aspects of reliability techniques as well as understand the relationship between reliability and validity."

**Quick Take**: Think of validity threats as alternative explanations for your results—good research design eliminates these alternatives so your conclusions stand on solid ground.

### Applied vs. Basic Research

Understanding whether you're conducting basic or applied research shapes your entire approach. Basic research advances theoretical understanding of fundamental processes, while applied research solves immediate practical problems. Both are valuable and often interconnected—basic research provides the foundation for applied solutions, while applied research identifies gaps that basic research needs to address. The most successful researchers can move fluidly between both approaches, using theoretical insights to solve practical problems and practical challenges to inform theoretical development.

> "The purpose of basic research is to provide an understanding of existing knowledge, and applied research is used to predict a phenomenon of interest or how someone would behave in a given situation."

**Quick Take**: Clarify whether your goal is understanding (basic) or prediction/application (applied)—this determines everything from your research questions to how you'll measure success.

## Best Quotes

- "After reading this book and understanding research design and threats to validity, you will be able to improve the validity of conducting research at work or critically evaluating existing research results to better understand how to interpret research."

- "Think about it for a minute. How would you like to have the ability to know any potential problem you would encounter and how to fix it before it actually happens?"

- "Research methodology would not be complete without an in-depth discussion of reliability and validity. Besides, reliability and validity are the crux of conducting quality research."

- "The best predictor of future behavior is past behavior. This statement is the result of conducting research!"

- "No research study is perfect in its design and execution, and a researcher should be prepared to address any issues in the discussion section of the research report."

## Action Items

- Always start with clear research questions that can be empirically tested rather than vague curiosities
- Match your research design to your practical constraints rather than trying to force ideal conditions
- Build reliability and validity considerations into your design from the beginning, not as afterthoughts
- Develop detailed protocols for data collection and measurement before starting your research
- Create a comprehensive ethical review process that includes informed consent and confidentiality protections
- Plan for alternative explanations and validity threats before collecting data
- Document your methodology thoroughly so others can replicate and build upon your work

## Questions to Consider

- Are you trying to understand fundamental processes (basic research) or solve practical problems (applied research)?
- What alternative explanations might exist for your expected results, and how can you design your study to eliminate them?
- How will you ensure your measurements are both reliable and valid?
- What ethical considerations are unique to your research context and participant population?
- Can your findings be generalized to other settings, populations, or time periods?
- What are the practical implications of your research for real-world decision-making?
- How will you address the inevitable limitations and weaknesses in your study design?

## Conclusion

**Is this worth your time?** Absolutely. This book transforms abstract research methodology into practical tools that anyone can apply in professional settings. It's particularly valuable for practitioners who need to conduct research in organizations, students transitioning from academic to applied settings, or anyone who wants to become a more critical consumer of research information.

**What's the biggest reason to read it?** The book's emphasis on bridging the science-practice gap makes it unique among research methods textbooks. Rather than presenting research as a purely academic exercise, Picardi and Masick demonstrate how rigorous methodology can solve real organizational problems while advancing scientific knowledge. This dual focus on both academic rigor and practical application provides readers with skills that are immediately valuable in any professional context that requires evidence-based decision-making.

The book succeeds by making complex concepts accessible without oversimplifying them, providing concrete examples from organizational settings, and maintaining a consistent focus on the relationship between research quality and practical impact. Readers will finish with both the confidence to conduct their own research and the critical skills to evaluate others' research findings effectively.